1:"$Sreact.fragment"
2:I[16501,["771","static/chunks/771-6df7383af9cb22cb.js","732","static/chunks/732-1930f1f7bd6746a5.js","13","static/chunks/13-f12e2db1f59fda05.js","355","static/chunks/355-f98f115f8c6f56c6.js","177","static/chunks/app/layout-be7f58cf6f9b9f21.js"],"Provider"]
3:I[9766,[],""]
4:I[98924,[],""]
5:I[58923,["771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","335","static/chunks/app/%5Bslug%5D/error-b2784470a4722ef4.js"],"default"]
6:I[52619,["150","static/chunks/59650de3-92bcb3811df53909.js","771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","732","static/chunks/732-1930f1f7bd6746a5.js","619","static/chunks/619-f072ac750404f9da.js","909","static/chunks/909-5e57b886fe664200.js","13","static/chunks/13-f12e2db1f59fda05.js","785","static/chunks/785-90bb983d5bf6562b.js","767","static/chunks/767-6b739569ff79f765.js","609","static/chunks/609-e6afbba7cf646b18.js","182","static/chunks/app/%5Bslug%5D/page-2d806954bbec0f0a.js"],""]
7:I[54921,["150","static/chunks/59650de3-92bcb3811df53909.js","771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","732","static/chunks/732-1930f1f7bd6746a5.js","619","static/chunks/619-f072ac750404f9da.js","909","static/chunks/909-5e57b886fe664200.js","13","static/chunks/13-f12e2db1f59fda05.js","785","static/chunks/785-90bb983d5bf6562b.js","767","static/chunks/767-6b739569ff79f765.js","609","static/chunks/609-e6afbba7cf646b18.js","182","static/chunks/app/%5Bslug%5D/page-2d806954bbec0f0a.js"],"Button"]
9:I[24431,[],"OutletBoundary"]
b:I[15278,[],"AsyncMetadataOutlet"]
d:I[24431,[],"ViewportBoundary"]
f:I[24431,[],"MetadataBoundary"]
10:"$Sreact.suspense"
12:I[57150,[],""]
:HL["/kouchouAI-reports/_next/static/css/a63443551c7d7d9f.css","style"]
0:{"P":null,"b":"3b2kFua5oe-8CgSo307Vs","p":"/kouchouAI-reports","c":["","99b00a75-d481-48bf-9133-8976f6f7720c",""],"i":false,"f":[[["",{"children":[["slug","99b00a75-d481-48bf-9133-8976f6f7720c","d"],{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/kouchouAI-reports/_next/static/css/a63443551c7d7d9f.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"suppressHydrationWarning":true,"lang":"ja","children":[["$","head",null,{"children":[["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":"anonymous"}],["$","link",null,{"href":"https://fonts.googleapis.com/css2?family=BIZ+UDPGothic&display=swap","rel":"stylesheet"}],["$","link",null,{"rel":"icon","href":"/kouchouAI-reports/meta/icon.png","sizes":"any"}],false]}],["$","body",null,{"children":["$","$L2",null,{"children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}]]}],{"children":[["slug","99b00a75-d481-48bf-9133-8976f6f7720c","d"],["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$5","errorStyles":[],"errorScripts":[],"template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","p",null,{"children":"ページが見つかりませんでした"}],["$","$L6",null,{"href":"/","children":["$","$L7",null,{"children":"トップに戻る"}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L8",null,["$","$L9",null,{"children":["$La",["$","$Lb",null,{"promise":"$@c"}]]}]]}],{},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,[["$","$Ld",null,{"children":"$Le"}],null],["$","$Lf",null,{"children":["$","div",null,{"hidden":true,"children":["$","$10",null,{"fallback":null,"children":"$L11"}]}]}]]}],false]],"m":"$undefined","G":["$12",[]],"s":false,"S":true}
e:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
a:null
13:I[67733,["150","static/chunks/59650de3-92bcb3811df53909.js","771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","732","static/chunks/732-1930f1f7bd6746a5.js","619","static/chunks/619-f072ac750404f9da.js","909","static/chunks/909-5e57b886fe664200.js","13","static/chunks/13-f12e2db1f59fda05.js","785","static/chunks/785-90bb983d5bf6562b.js","767","static/chunks/767-6b739569ff79f765.js","609","static/chunks/609-e6afbba7cf646b18.js","182","static/chunks/app/%5Bslug%5D/page-2d806954bbec0f0a.js"],"Header"]
14:I[99347,["150","static/chunks/59650de3-92bcb3811df53909.js","771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","732","static/chunks/732-1930f1f7bd6746a5.js","619","static/chunks/619-f072ac750404f9da.js","909","static/chunks/909-5e57b886fe664200.js","13","static/chunks/13-f12e2db1f59fda05.js","785","static/chunks/785-90bb983d5bf6562b.js","767","static/chunks/767-6b739569ff79f765.js","609","static/chunks/609-e6afbba7cf646b18.js","182","static/chunks/app/%5Bslug%5D/page-2d806954bbec0f0a.js"],"Box"]
15:I[55756,["150","static/chunks/59650de3-92bcb3811df53909.js","771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","732","static/chunks/732-1930f1f7bd6746a5.js","619","static/chunks/619-f072ac750404f9da.js","909","static/chunks/909-5e57b886fe664200.js","13","static/chunks/13-f12e2db1f59fda05.js","785","static/chunks/785-90bb983d5bf6562b.js","767","static/chunks/767-6b739569ff79f765.js","609","static/chunks/609-e6afbba7cf646b18.js","182","static/chunks/app/%5Bslug%5D/page-2d806954bbec0f0a.js"],"Heading"]
16:I[48409,["150","static/chunks/59650de3-92bcb3811df53909.js","771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","732","static/chunks/732-1930f1f7bd6746a5.js","619","static/chunks/619-f072ac750404f9da.js","909","static/chunks/909-5e57b886fe664200.js","13","static/chunks/13-f12e2db1f59fda05.js","785","static/chunks/785-90bb983d5bf6562b.js","767","static/chunks/767-6b739569ff79f765.js","609","static/chunks/609-e6afbba7cf646b18.js","182","static/chunks/app/%5Bslug%5D/page-2d806954bbec0f0a.js"],"Text"]
17:I[92091,["150","static/chunks/59650de3-92bcb3811df53909.js","771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","732","static/chunks/732-1930f1f7bd6746a5.js","619","static/chunks/619-f072ac750404f9da.js","909","static/chunks/909-5e57b886fe664200.js","13","static/chunks/13-f12e2db1f59fda05.js","785","static/chunks/785-90bb983d5bf6562b.js","767","static/chunks/767-6b739569ff79f765.js","609","static/chunks/609-e6afbba7cf646b18.js","182","static/chunks/app/%5Bslug%5D/page-2d806954bbec0f0a.js"],"Icon"]
18:I[6026,["150","static/chunks/59650de3-92bcb3811df53909.js","771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","732","static/chunks/732-1930f1f7bd6746a5.js","619","static/chunks/619-f072ac750404f9da.js","909","static/chunks/909-5e57b886fe664200.js","13","static/chunks/13-f12e2db1f59fda05.js","785","static/chunks/785-90bb983d5bf6562b.js","767","static/chunks/767-6b739569ff79f765.js","609","static/chunks/609-e6afbba7cf646b18.js","182","static/chunks/app/%5Bslug%5D/page-2d806954bbec0f0a.js"],"ClientContainer"]
19:T194c,import concurrent.futures
import json
import logging
import os
import re

import pandas as pd
from pydantic import BaseModel, Field
from tqdm import tqdm

from services.llm import request_to_chat_ai
from services.parse_json_list import parse_extraction_response
from utils import update_progress

COMMA_AND_SPACE_AND_RIGHT_BRACKET = re.compile(r",\s*(\])")


class ExtractionResponse(BaseModel):
    extractedOpinionList: list[str] = Field(..., description="抽出した意見のリスト")


def _validate_property_columns(property_columns: list[str], comments: pd.DataFrame) -> None:
    if not all(property in comments.columns for property in property_columns):
        raise ValueError(f"Properties {property_columns} not found in comments. Columns are {comments.columns}")


def extraction(config):
    dataset = config["output_dir"]
    path = f"outputs/{dataset}/args.csv"
    model = config["extraction"]["model"]
    prompt = config["extraction"]["prompt"]
    workers = config["extraction"]["workers"]
    limit = config["extraction"]["limit"]
    property_columns = config["extraction"]["properties"]

    if "provider" not in config:
        raise RuntimeError("provider is not set")
    provider = config["provider"]

    # カラム名だけを読み込み、必要なカラムが含まれているか確認する
    comments = pd.read_csv(f"inputs/{config['input']}.csv", nrows=0)
    _validate_property_columns(property_columns, comments)
    # エラーが出なかった場合、すべての行を読み込む
    comments = pd.read_csv(
        f"inputs/{config['input']}.csv", usecols=["comment-id", "comment-body"] + config["extraction"]["properties"]
    )
    comment_ids = (comments["comment-id"].values)[:limit]
    comments.set_index("comment-id", inplace=True)
    results = pd.DataFrame()
    update_progress(config, total=len(comment_ids))

    argument_map = {}
    relation_rows = []

    for i in tqdm(range(0, len(comment_ids), workers)):
        batch = comment_ids[i : i + workers]
        batch_inputs = [comments.loc[id]["comment-body"] for id in batch]
        batch_results = extract_batch(
            batch_inputs, prompt, model, workers, provider, config.get("local_llm_address"), config
        )

        for comment_id, extracted_args in zip(batch, batch_results, strict=False):
            for j, arg in enumerate(extracted_args):
                if arg not in argument_map:
                    # argumentテーブルに追加
                    arg_id = f"A{comment_id}_{j}"
                    argument = arg
                    argument_map[arg] = {
                        "arg-id": arg_id,
                        "argument": argument,
                    }
                else:
                    arg_id = argument_map[arg]["arg-id"]

                # relationテーブルにcommentとargの関係を追加
                relation_row = {
                    "arg-id": arg_id,
                    "comment-id": comment_id,
                }
                relation_rows.append(relation_row)

        update_progress(config, incr=len(batch))

    # DataFrame化
    results = pd.DataFrame(argument_map.values())
    relation_df = pd.DataFrame(relation_rows)

    if results.empty:
        raise RuntimeError("result is empty, maybe bad prompt")

    results.to_csv(path, index=False)
    # comment-idとarg-idの関係を保存
    relation_df.to_csv(f"outputs/{dataset}/relations.csv", index=False)


logging.basicConfig(level=logging.DEBUG)


def extract_batch(batch, prompt, model, workers, provider="openai", local_llm_address=None, config=None):
    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:
        futures_with_index = [
            (i, executor.submit(extract_arguments, input, prompt, model, provider, local_llm_address))
            for i, input in enumerate(batch)
        ]

        done, not_done = concurrent.futures.wait([f for _, f in futures_with_index], timeout=30)
        results = [[] for _ in range(len(batch))]
        total_token_input = 0
        total_token_output = 0
        total_token_usage = 0

        for _, future in futures_with_index:
            if future in not_done and not future.cancelled():
                future.cancel()

        for i, future in futures_with_index:
            if future in done:
                try:
                    result = future.result()
                    if isinstance(result, tuple) and len(result) == 4:
                        items, token_input, token_output, token_total = result
                        results[i] = items
                        total_token_input += token_input
                        total_token_output += token_output
                        total_token_usage += token_total
                    else:
                        results[i] = result
                except Exception as e:
                    logging.error(f"Task {future} failed with error: {e}")
                    results[i] = []

        if config is not None:
            config["total_token_usage"] = config.get("total_token_usage", 0) + total_token_usage
            config["token_usage_input"] = config.get("token_usage_input", 0) + total_token_input
            config["token_usage_output"] = config.get("token_usage_output", 0) + total_token_output
            print(
                f"Extraction batch: input={total_token_input}, output={total_token_output}, total={total_token_usage} tokens"
            )

        return results


def extract_arguments(input, prompt, model, provider="openai", local_llm_address=None):
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": input},
    ]
    try:
        response, token_input, token_output, token_total = request_to_chat_ai(
            messages=messages,
            model=model,
            is_json=False,
            json_schema=ExtractionResponse,
            provider=provider,
            local_llm_address=local_llm_address,
            user_api_key=os.getenv("USER_API_KEY"),
        )
        items = parse_extraction_response(response)
        items = list(filter(None, items))  # omit empty strings
        return items, token_input, token_output, token_total
    except json.decoder.JSONDecodeError as e:
        print("JSON error:", e)
        print("Input was:", input)
        print("Response was:", response)
        print("Silently giving up on trying to generate valid list.")
        return []
1a:T1149,"""Cluster the arguments using UMAP + HDBSCAN and GPT-4."""

from importlib import import_module

import numpy as np
import pandas as pd
import scipy.cluster.hierarchy as sch
from sklearn.cluster import KMeans


def hierarchical_clustering(config):
    UMAP = import_module("umap").UMAP

    dataset = config["output_dir"]
    path = f"outputs/{dataset}/hierarchical_clusters.csv"
    arguments_df = pd.read_csv(f"outputs/{dataset}/args.csv", usecols=["arg-id", "argument"])
    embeddings_df = pd.read_pickle(f"outputs/{dataset}/embeddings.pkl")
    embeddings_array = np.asarray(embeddings_df["embedding"].values.tolist())
    cluster_nums = config["hierarchical_clustering"]["cluster_nums"]

    n_samples = embeddings_array.shape[0]
    # デフォルト設定は15
    default_n_neighbors = 15

    # テスト等サンプルが少なすぎる場合、n_neighborsの設定値を下げる
    if n_samples <= default_n_neighbors:
        n_neighbors = max(2, n_samples - 1)  # 最低2以上
    else:
        n_neighbors = default_n_neighbors

    umap_model = UMAP(random_state=42, n_components=2, n_neighbors=n_neighbors)
    # TODO 詳細エラーメッセージを加える
    # 以下のエラーの場合、おそらく元の意見件数が少なすぎることが原因
    # TypeError: Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.
    umap_embeds = umap_model.fit_transform(embeddings_array)

    cluster_results = hierarchical_clustering_embeddings(
        umap_embeds=umap_embeds,
        cluster_nums=cluster_nums,
    )
    result_df = pd.DataFrame(
        {
            "arg-id": arguments_df["arg-id"],
            "argument": arguments_df["argument"],
            "x": umap_embeds[:, 0],
            "y": umap_embeds[:, 1],
        }
    )

    for cluster_level, final_labels in enumerate(cluster_results.values(), start=1):
        result_df[f"cluster-level-{cluster_level}-id"] = [f"{cluster_level}_{label}" for label in final_labels]

    result_df.to_csv(path, index=False)


def generate_cluster_count_list(min_clusters: int, max_clusters: int):
    cluster_counts = []
    current = min_clusters
    cluster_counts.append(current)

    if min_clusters == max_clusters:
        return cluster_counts

    while True:
        next_double = current * 2
        next_triple = current * 3

        if next_double >= max_clusters:
            if cluster_counts[-1] != max_clusters:
                cluster_counts.append(max_clusters)
            break

        # 次の倍はまだ max_clusters に収まるが、3倍だと超える
        # -> (次の倍は細かすぎるので)スキップして max_clusters に飛ぶ
        if next_triple > max_clusters:
            cluster_counts.append(max_clusters)
            break

        cluster_counts.append(next_double)
        current = next_double

    return cluster_counts


def merge_clusters_with_hierarchy(
    cluster_centers: np.ndarray,
    kmeans_labels: np.ndarray,
    umap_array: np.ndarray,
    n_cluster_cut: int,
):
    Z = sch.linkage(cluster_centers, method="ward")
    cluster_labels_merged = sch.fcluster(Z, t=n_cluster_cut, criterion="maxclust")

    n_samples = umap_array.shape[0]
    final_labels = np.zeros(n_samples, dtype=int)

    for i in range(n_samples):
        original_label = kmeans_labels[i]
        final_labels[i] = cluster_labels_merged[original_label]

    return final_labels


def hierarchical_clustering_embeddings(
    umap_embeds,
    cluster_nums,
):
    # 最大分割数でクラスタリングを実施
    print("start initial clustering")
    initial_cluster_num = cluster_nums[-1]
    kmeans_model = KMeans(n_clusters=initial_cluster_num, random_state=42)
    kmeans_model.fit(umap_embeds)
    print("end initial clustering")

    results = {}
    print("start hierarchical clustering")
    cluster_nums.sort()
    print(cluster_nums)
    for n_cluster_cut in cluster_nums[:-1]:
        print("n_cluster_cut: ", n_cluster_cut)
        final_labels = merge_clusters_with_hierarchy(
            cluster_centers=kmeans_model.cluster_centers_,
            kmeans_labels=kmeans_model.labels_,
            umap_array=umap_embeds,
            n_cluster_cut=n_cluster_cut,
        )
        results[n_cluster_cut] = final_labels

    results[initial_cluster_num] = kmeans_model.labels_
    print("end hierarchical clustering")

    return results
1b:T1c36,import json
import os
from concurrent.futures import ThreadPoolExecutor
from functools import partial
from typing import TypedDict

import pandas as pd
from pydantic import BaseModel, Field

from services.llm import request_to_chat_ai


class LabellingResult(TypedDict):
    """各クラスタのラベリング結果を表す型"""

    cluster_id: str  # クラスタのID
    label: str  # クラスタのラベル名
    description: str  # クラスタの説明文


def hierarchical_initial_labelling(config: dict) -> None:
    """階層的クラスタリングの初期ラベリングを実行する

    Args:
        config: 設定情報を含む辞書
            - output_dir: 出力ディレクトリ名
            - hierarchical_initial_labelling: 初期ラベリングの設定
                - sampling_num: サンプリング数
                - prompt: LLMへのプロンプト
                - model: 使用するLLMモデル名
                - workers: 並列処理のワーカー数
            - provider: LLMプロバイダー
    """
    dataset = config["output_dir"]
    path = f"outputs/{dataset}/hierarchical_initial_labels.csv"
    clusters_argument_df = pd.read_csv(f"outputs/{dataset}/hierarchical_clusters.csv")

    cluster_id_columns = [col for col in clusters_argument_df.columns if col.startswith("cluster-level-")]
    initial_cluster_id_column = cluster_id_columns[-1]
    sampling_num = config["hierarchical_initial_labelling"]["sampling_num"]
    initial_labelling_prompt = config["hierarchical_initial_labelling"]["prompt"]
    model = config["hierarchical_initial_labelling"]["model"]
    workers = config["hierarchical_initial_labelling"]["workers"]

    # トークン使用量を追跡するための変数を初期化
    config["total_token_usage"] = config.get("total_token_usage", 0)

    initial_label_df = initial_labelling(
        initial_labelling_prompt,
        clusters_argument_df,
        sampling_num,
        model,
        workers,
        config["provider"],
        config.get("local_llm_address"),
        config,  # configを渡して、トークン使用量を累積できるようにする
    )
    print("start initial labelling")
    initial_clusters_argument_df = clusters_argument_df.merge(
        initial_label_df,
        left_on=initial_cluster_id_column,
        right_on="cluster_id",
        how="left",
    ).rename(
        columns={
            "label": f"{initial_cluster_id_column.replace('-id', '')}-label",
            "description": f"{initial_cluster_id_column.replace('-id', '')}-description",
        }
    )
    print("end initial labelling")
    initial_clusters_argument_df.to_csv(path, index=False)


def initial_labelling(
    prompt: str,
    clusters_df: pd.DataFrame,
    sampling_num: int,
    model: str,
    workers: int,
    provider: str = "openai",
    local_llm_address: str | None = None,
    config: dict | None = None,  # configを追加
) -> pd.DataFrame:
    """各クラスタに対して初期ラベリングを実行する

    Args:
        prompt: LLMへのプロンプト
        clusters_df: クラスタリング結果のDataFrame
        sampling_num: 各クラスタからサンプリングする意見の数
        model: 使用するLLMモデル名
        workers: 並列処理のワーカー数
        provider: LLMプロバイダー
        local_llm_address: ローカルLLMのアドレス
        config: 設定情報を含む辞書（トークン使用量の累積に使用）

    Returns:
        各クラスタのラベリング結果を含むDataFrame
    """
    cluster_columns = [col for col in clusters_df.columns if col.startswith("cluster-level-")]
    initial_cluster_column = cluster_columns[-1]
    cluster_ids = clusters_df[initial_cluster_column].unique()
    process_func = partial(
        process_initial_labelling,
        df=clusters_df,
        prompt=prompt,
        sampling_num=sampling_num,
        target_column=initial_cluster_column,
        model=model,
        provider=provider,
        local_llm_address=local_llm_address,
        config=config,  # configを渡す
    )
    with ThreadPoolExecutor(max_workers=workers) as executor:
        results = list(executor.map(process_func, cluster_ids))
    return pd.DataFrame(results)


class LabellingFromat(BaseModel):
    """ラベリング結果のフォーマットを定義する"""

    label: str = Field(..., description="クラスタのラベル名")
    description: str = Field(..., description="クラスタの説明文")


def process_initial_labelling(
    cluster_id: str,
    df: pd.DataFrame,
    prompt: str,
    sampling_num: int,
    target_column: str,
    model: str,
    provider: str = "openai",
    local_llm_address: str | None = None,
    config: dict | None = None,  # configを追加
) -> LabellingResult:
    """個別のクラスタに対してラベリングを実行する

    Args:
        cluster_id: 処理対象のクラスタID
        df: クラスタリング結果のDataFrame
        prompt: LLMへのプロンプト
        sampling_num: サンプリングする意見の数
        target_column: クラスタIDが格納されている列名
        model: 使用するLLMモデル名
        provider: LLMプロバイダー
        local_llm_address: ローカルLLMのアドレス
        config: 設定情報を含む辞書（トークン使用量の累積に使用）

    Returns:
        クラスタのラベリング結果
    """
    cluster_data = df[df[target_column] == cluster_id]
    sampling_num = min(sampling_num, len(cluster_data))
    cluster = cluster_data.sample(sampling_num)
    input = "\n".join(cluster["argument"].values)
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": input},
    ]
    try:
        response_text, token_input, token_output, token_total = request_to_chat_ai(
            messages=messages,
            model=model,
            provider=provider,
            json_schema=LabellingFromat,
            local_llm_address=local_llm_address,
            user_api_key=os.getenv("USER_API_KEY"),
        )

        # トークン使用量を累積（configが渡されている場合）
        if config is not None:
            config["total_token_usage"] = config.get("total_token_usage", 0) + token_total
            config["token_usage_input"] = config.get("token_usage_input", 0) + token_input
            config["token_usage_output"] = config.get("token_usage_output", 0) + token_output

        response_json = json.loads(response_text) if isinstance(response_text, str) else response_text
        return LabellingResult(
            cluster_id=cluster_id,
            label=response_json.get("label", "エラーでラベル名が取得できませんでした"),
            description=response_json.get("description", "エラーで解説が取得できませんでした"),
        )
    except Exception as e:
        print(e)
        return LabellingResult(
            cluster_id=cluster_id,
            label="エラーでラベル名が取得できませんでした",
            description="エラーで解説が取得できませんでした",
        )
1c:T337b,import json
import os
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from functools import partial

import numpy as np
import pandas as pd
from pydantic import BaseModel, Field
from tqdm import tqdm

from services.llm import request_to_chat_ai


@dataclass
class ClusterColumns:
    """同一階層のクラスター関連のカラム名を管理するクラス"""

    id: str
    label: str
    description: str

    @classmethod
    def from_id_column(cls, id_column: str) -> "ClusterColumns":
        """ID列名から関連するカラム名を生成"""
        return cls(
            id=id_column,
            label=id_column.replace("-id", "-label"),
            description=id_column.replace("-id", "-description"),
        )


@dataclass
class ClusterValues:
    """対象クラスタのlabel/descriptionを管理するクラス"""

    label: str
    description: str

    def to_prompt_text(self) -> str:
        return f"- {self.label}: {self.description}"


def hierarchical_merge_labelling(config: dict) -> None:
    """階層的クラスタリングの結果に対してマージラベリングを実行する

    Args:
        config: 設定情報を含む辞書
            - output_dir: 出力ディレクトリ名
            - hierarchical_merge_labelling: マージラベリングの設定
                - sampling_num: サンプリング数
                - prompt: LLMへのプロンプト
                - model: 使用するLLMモデル名
                - workers: 並列処理のワーカー数
            - provider: LLMプロバイダー
    """
    dataset = config["output_dir"]
    merge_path = f"outputs/{dataset}/hierarchical_merge_labels.csv"
    clusters_df = pd.read_csv(f"outputs/{dataset}/hierarchical_initial_labels.csv")

    cluster_id_columns: list[str] = _filter_id_columns(clusters_df.columns)
    # ボトムクラスタのラベル・説明とクラスタid付きの各argumentを入力し、各階層のクラスタラベル・説明を生成し、argumentに付けたdfを作成
    merge_result_df = merge_labelling(
        clusters_df=clusters_df,
        cluster_id_columns=sorted(cluster_id_columns, reverse=True),
        config=config,
    )
    # 上記のdfから各クラスタのlevel, id, label, description, valueを取得してdfを作成
    melted_df = melt_cluster_data(merge_result_df)
    # 上記のdfに親子関係を追加
    parent_child_df = _build_parent_child_mapping(merge_result_df, cluster_id_columns)
    melted_df = melted_df.merge(parent_child_df, on=["level", "id"], how="left")
    density_df = calculate_cluster_density(melted_df, config)
    density_df.to_csv(merge_path, index=False)


def _build_parent_child_mapping(df: pd.DataFrame, cluster_id_columns: list[str]):
    """クラスタ間の親子関係をマッピングする

    Args:
        df: クラスタリング結果のDataFrame
        cluster_id_columns: クラスタIDのカラム名のリスト

    Returns:
        親子関係のマッピング情報を含むDataFrame
    """
    results = []
    top_cluster_column = cluster_id_columns[0]
    top_cluster_values = df[top_cluster_column].unique()
    for c in top_cluster_values:
        results.append(
            {
                "level": 1,
                "id": c,
                "parent": "0",  # aggregationで追加する全体クラスタのid
            }
        )

    for idx in range(len(cluster_id_columns) - 1):
        current_column = cluster_id_columns[idx]
        children_column = cluster_id_columns[idx + 1]
        current_level = current_column.replace("-id", "").replace("cluster-level-", "")
        # 現在のレベルのクラスタid
        current_cluster_values = df[current_column].unique()
        for current_id in current_cluster_values:
            children_ids = df.loc[df[current_column] == current_id, children_column].unique()
            for child_id in children_ids:
                results.append(
                    {
                        "level": int(current_level) + 1,
                        "id": child_id,
                        "parent": current_id,
                    }
                )
    return pd.DataFrame(results)


def _filter_id_columns(columns: list[str]) -> list[str]:
    """クラスタIDのカラム名をフィルタリングする

    Args:
        columns: 全カラム名のリスト

    Returns:
        クラスタIDのカラム名のリスト
    """
    return [col for col in columns if col.startswith("cluster-level-") and col.endswith("-id")]


def melt_cluster_data(df: pd.DataFrame) -> pd.DataFrame:
    """クラスタデータを行形式に変換する

    cluster-level-n-(id|label|description) を行形式 (level, id, label, description, value) にまとめる。
    [cluster-level-n-id, cluster-level-n-label, cluster-level-n-description] を [level, id, label, description, value(件数)] に変換する。

    Args:
        df: クラスタリング結果のDataFrame

    Returns:
        行形式に変換されたDataFrame
    """
    id_columns: list[str] = _filter_id_columns(df.columns)
    levels: set[int] = {int(col.replace("cluster-level-", "").replace("-id", "")) for col in id_columns}
    all_rows: list[dict] = []

    # levelごとに各クラスタの出現件数を集計・縦持ちにする
    for level in levels:
        cluster_columns = ClusterColumns.from_id_column(f"cluster-level-{level}-id")
        # クラスタidごとの件数集計
        level_count_df = df.groupby(cluster_columns.id).size().reset_index(name="value")

        level_unique_val_df = df[
            [cluster_columns.id, cluster_columns.label, cluster_columns.description]
        ].drop_duplicates()
        level_unique_val_df = level_unique_val_df.merge(level_count_df, on=cluster_columns.id, how="left")
        level_unique_vals = [
            {
                "level": level,
                "id": row[cluster_columns.id],
                "label": row[cluster_columns.label],
                "description": row[cluster_columns.description],
                "value": row["value"],
            }
            for _, row in level_unique_val_df.iterrows()
        ]
        all_rows.extend(level_unique_vals)
    return pd.DataFrame(all_rows)


def merge_labelling(clusters_df: pd.DataFrame, cluster_id_columns: list[str], config) -> pd.DataFrame:
    """階層的なクラスタのマージラベリングを実行する

    Args:
        clusters_df: クラスタリング結果のDataFrame
        cluster_id_columns: クラスタIDのカラム名のリスト
        config: 設定情報を含む辞書

    Returns:
        マージラベリング結果を含むDataFrame
    """
    for idx in tqdm(range(len(cluster_id_columns) - 1)):
        previous_columns = ClusterColumns.from_id_column(cluster_id_columns[idx])
        current_columns = ClusterColumns.from_id_column(cluster_id_columns[idx + 1])

        process_fn = partial(
            process_merge_labelling,
            result_df=clusters_df,
            current_columns=current_columns,
            previous_columns=previous_columns,
            config=config,
        )

        current_cluster_ids = sorted(clusters_df[current_columns.id].unique())
        with ThreadPoolExecutor(max_workers=config["hierarchical_merge_labelling"]["workers"]) as executor:
            responses = list(
                tqdm(
                    executor.map(process_fn, current_cluster_ids),
                    total=len(current_cluster_ids),
                )
            )

        current_result_df = pd.DataFrame(responses)
        clusters_df = clusters_df.merge(current_result_df, on=[current_columns.id])
    return clusters_df


class LabellingFromat(BaseModel):
    """ラベリング結果のフォーマットを定義する"""

    label: str = Field(..., description="クラスタのラベル名")
    description: str = Field(..., description="クラスタの説明文")


def process_merge_labelling(
    target_cluster_id: str,
    result_df: pd.DataFrame,
    current_columns: ClusterColumns,
    previous_columns: ClusterColumns,
    config,
):
    """個別のクラスタに対してマージラベリングを実行する

    Args:
        target_cluster_id: 処理対象のクラスタID
        result_df: クラスタリング結果のDataFrame
        current_columns: 現在のレベルのカラム情報
        previous_columns: 前のレベルのカラム情報
        config: 設定情報を含む辞書

    Returns:
        マージラベリング結果を含む辞書
    """

    def filter_previous_values(df: pd.DataFrame, previous_columns: ClusterColumns) -> list[ClusterValues]:
        """前のレベルのクラスタ情報を取得する"""
        previous_records = df[df[current_columns.id] == target_cluster_id][
            [previous_columns.label, previous_columns.description]
        ].drop_duplicates()
        previous_values = [
            ClusterValues(
                label=row[previous_columns.label],
                description=row[previous_columns.description],
            )
            for _, row in previous_records.iterrows()
        ]
        return previous_values

    previous_values = filter_previous_values(result_df, previous_columns)
    if len(previous_values) == 1:
        return {
            current_columns.id: target_cluster_id,
            current_columns.label: previous_values[0].label,
            current_columns.description: previous_values[0].description,
        }
    elif len(previous_values) == 0:
        raise ValueError(f"クラスタ {target_cluster_id} には前のレベルのクラスタが存在しません。")

    current_cluster_data = result_df[result_df[current_columns.id] == target_cluster_id]
    sampling_num = min(
        config["hierarchical_merge_labelling"]["sampling_num"],
        len(current_cluster_data),
    )
    sampled_data = current_cluster_data.sample(sampling_num)
    sampled_argument_text = "\n".join(sampled_data["argument"].values)
    cluster_text = "\n".join([value.to_prompt_text() for value in previous_values])
    messages = [
        {"role": "system", "content": config["hierarchical_merge_labelling"]["prompt"]},
        {
            "role": "user",
            "content": "クラスタラベル\n" + cluster_text + "\n" + "クラスタの意見\n" + sampled_argument_text,
        },
    ]
    try:
        response_text, token_input, token_output, token_total = request_to_chat_ai(
            messages=messages,
            model=config["hierarchical_merge_labelling"]["model"],
            json_schema=LabellingFromat,
            provider=config["provider"],
            local_llm_address=config.get("local_llm_address"),
            user_api_key=os.getenv("USER_API_KEY"),
        )

        config["total_token_usage"] = config.get("total_token_usage", 0) + token_total
        config["token_usage_input"] = config.get("token_usage_input", 0) + token_input
        config["token_usage_output"] = config.get("token_usage_output", 0) + token_output
        print(f"Merge labelling: input={token_input}, output={token_output}, total={token_total} tokens")

        response_json = json.loads(response_text) if isinstance(response_text, str) else response_text
        return {
            current_columns.id: target_cluster_id,
            current_columns.label: response_json.get("label", "エラーでラベル名が取得できませんでした"),
            current_columns.description: response_json.get("description", "エラーで解説が取得できませんでした"),
        }
    except Exception as e:
        print(f"エラーが発生しました: {e}")
        return {
            current_columns.id: target_cluster_id,
            current_columns.label: "エラーでラベル名が取得できませんでした",
            current_columns.description: "エラーで解説が取得できませんでした",
        }


def calculate_cluster_density(melted_df: pd.DataFrame, config: dict):
    """クラスタ内の密度計算"""
    hierarchical_cluster_df = pd.read_csv(f"outputs/{config['output_dir']}/hierarchical_clusters.csv")

    densities = []
    for level, c_id in zip(melted_df["level"], melted_df["id"], strict=False):
        cluster_embeds = hierarchical_cluster_df[hierarchical_cluster_df[f"cluster-level-{level}-id"] == c_id][
            ["x", "y"]
        ].values
        density = calculate_density(cluster_embeds)
        densities.append(density)

    # 密度のランクを計算
    melted_df["density"] = densities
    melted_df["density_rank"] = melted_df.groupby("level")["density"].rank(ascending=False, method="first")
    melted_df["density_rank_percentile"] = melted_df.groupby("level")["density_rank"].transform(lambda x: x / len(x))
    return melted_df


def calculate_density(embeds: np.ndarray):
    """平均距離に基づいて密度を計算"""
    center = np.mean(embeds, axis=0)
    distances = np.linalg.norm(embeds - center, axis=1)
    avg_distance = np.mean(distances)
    density = 1 / (avg_distance + 1e-10)
    return density
1d:Ta82,"""Create summaries for the clusters."""

import json
import os
import re

import pandas as pd
from pydantic import BaseModel, Field

from services.llm import request_to_chat_ai


class OverviewResponse(BaseModel):
    summary: str = Field(..., description="クラスターの全体的な要約")


def hierarchical_overview(config):
    dataset = config["output_dir"]
    path = f"outputs/{dataset}/hierarchical_overview.txt"

    hierarchical_label_df = pd.read_csv(f"outputs/{dataset}/hierarchical_merge_labels.csv")

    prompt = config["hierarchical_overview"]["prompt"]
    model = config["hierarchical_overview"]["model"]

    # TODO: level1で固定にしているが、設定で変えられるようにする
    target_level = 1
    target_records = hierarchical_label_df[hierarchical_label_df["level"] == target_level]
    ids = target_records["id"].to_list()
    labels = target_records["label"].to_list()
    descriptions = target_records["description"].to_list()
    target_records.set_index("id", inplace=True)

    input_text = ""
    for i, _ in enumerate(ids):
        input_text += f"# Cluster {i}/{len(ids)}: {labels[i]}\n\n"
        input_text += descriptions[i] + "\n\n"

    messages = [{"role": "system", "content": prompt}, {"role": "user", "content": input_text}]
    response_text, token_input, token_output, token_total = request_to_chat_ai(
        messages=messages,
        model=model,
        provider=config["provider"],
        local_llm_address=config.get("local_llm_address"),
        user_api_key=os.getenv("USER_API_KEY"),
        json_schema=OverviewResponse,
    )

    # トークン使用量を累積
    config["total_token_usage"] = config.get("total_token_usage", 0) + token_total
    config["token_usage_input"] = config.get("token_usage_input", 0) + token_input
    config["token_usage_output"] = config.get("token_usage_output", 0) + token_output
    print(f"Hierarchical overview: input={token_input}, output={token_output}, total={token_total} tokens")

    try:
        # structured outputとしてパースできるなら処理する
        if isinstance(response_text, dict):
            parsed_response = response_text
        else:
            parsed_response = json.loads(response_text)

        with open(path, "w") as file:
            file.write(parsed_response["summary"])

    except Exception:
        # thinkタグが出力されるReasoningモデル用に、thinkタグを除去する
        thinking_removed = re.sub(
            r"<think\b[^>]*>.*?</think>",
            "",
            response_text,
            flags=re.DOTALL,
        )

        with open(path, "w") as file:
            file.write(thinking_removed)
1e:T3f38,"""Generate a convenient JSON output file."""

import json
from collections import defaultdict
from pathlib import Path
from typing import Any, TypedDict

import numpy as np
import pandas as pd

ROOT_DIR = Path(__file__).parent.parent.parent.parent
CONFIG_DIR = ROOT_DIR / "scatter" / "pipeline" / "configs"
PIPELINE_DIR = ROOT_DIR / "broadlistening" / "pipeline"


def json_serialize_numpy(obj: Any) -> Any:
    """
    Recursively convert NumPy data types to native Python types for JSON serialization.

    Args:
        obj: Any Python object which might contain NumPy data types

    Returns:
        The same object structure with NumPy types converted to Python native types
    """
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {k: json_serialize_numpy(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [json_serialize_numpy(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(json_serialize_numpy(item) for item in obj)
    else:
        return obj


class Argument(TypedDict):
    arg_id: str
    argument: str
    comment_id: str
    x: float
    y: float
    p: float
    cluster_ids: list[str]
    attributes: dict[str, str] | None
    url: str | None


class Cluster(TypedDict):
    level: int
    id: str
    label: str
    takeaway: str
    value: int
    parent: str
    density_rank_percentile: float | None


def hierarchical_aggregation(config) -> bool:
    try:
        path = f"outputs/{config['output_dir']}/hierarchical_result.json"
        results = {
            "arguments": [],
            "clusters": [],
            "comments": {},
            "propertyMap": {},
            "translations": {},
            "overview": "",
            "config": config,
        }

        arguments = pd.read_csv(f"outputs/{config['output_dir']}/args.csv")
        arguments.set_index("arg-id", inplace=True)
        arg_num = len(arguments)
        relation_df = pd.read_csv(f"outputs/{config['output_dir']}/relations.csv")
        comments = pd.read_csv(f"inputs/{config['input']}.csv")
        clusters = pd.read_csv(f"outputs/{config['output_dir']}/hierarchical_clusters.csv")
        labels = pd.read_csv(f"outputs/{config['output_dir']}/hierarchical_merge_labels.csv")

        hidden_properties_map: dict[str, list[str]] = config["hierarchical_aggregation"]["hidden_properties"]

        results["arguments"] = _build_arguments(clusters, comments, relation_df, config)
        results["clusters"] = _build_cluster_value(labels, arg_num)

        # results["comments"] = _build_comments_value(
        #     comments, arguments, hidden_properties_map
        # )
        results["comment_num"] = len(comments)
        results["translations"] = _build_translations(config)
        # 属性情報のカラムは、元データに対して指定したカラムとclassificationするカテゴリを合わせたもの
        results["propertyMap"] = _build_property_map(arguments, comments, hidden_properties_map, config)

        with open(f"outputs/{config['output_dir']}/hierarchical_overview.txt") as f:
            overview = f.read()
        print("overview")
        print(overview)
        results["overview"] = overview

        # Convert non-serializable NumPy types to native Python types
        results = json_serialize_numpy(results)

        with open(path, "w") as file:
            json.dump(results, file, indent=2, ensure_ascii=False)
        # TODO: サンプリングロジックを実装したいが、現状は全件抽出
        create_custom_intro(config)
        if config["is_pubcom"]:
            add_original_comments(labels, arguments, relation_df, clusters, config)
        return True
    except Exception as e:
        print("error")
        print(e)
        return False


def create_custom_intro(config):
    dataset = config["output_dir"]
    args_path = PIPELINE_DIR / f"outputs/{dataset}/args.csv"
    comments = pd.read_csv(PIPELINE_DIR / f"inputs/{config['input']}.csv")
    result_path = PIPELINE_DIR / f"outputs/{dataset}/hierarchical_result.json"

    input_count = len(comments)
    args_count = len(pd.read_csv(args_path))
    processed_num = min(input_count, config["extraction"]["limit"])

    print(f"Input count: {input_count}")
    print(f"Args count: {args_count}")

    # LLMプロバイダーとモデル名の判定
    def get_llm_provider_display():
        # configからプロバイダー情報を取得（優先）
        provider = config.get("provider", "openai")
        model = config.get("model", "unknown")

        # プロバイダー名をマッピング
        provider_names = {
            "openai": "OpenAI API",
            "azure": "Azure OpenAI API",
            "openrouter": "OpenRouter API",
            "local": "Local LLM",
        }

        provider_name = provider_names.get(provider, f"{provider} API")
        return f"{provider_name} ({model})"

    llm_provider = get_llm_provider_display()

    base_custom_intro = """{intro}
分析対象となったデータの件数は{processed_num}件で、これらのデータに対して{llm_provider}を用いて{args_count}件の意見（議論）を抽出し、クラスタリングを行った。
"""

    intro = config["intro"]
    custom_intro = base_custom_intro.format(
        intro=intro, processed_num=processed_num, args_count=args_count, llm_provider=llm_provider
    )

    with open(result_path) as f:
        result = json.load(f)
    result["config"]["intro"] = custom_intro
    with open(result_path, "w") as f:
        json.dump(result, f, indent=2, ensure_ascii=False)


def add_original_comments(labels, arguments, relation_df, clusters, config):
    # 大カテゴリ（cluster-level-1）に該当するラベルだけ抽出
    labels_lv1 = labels[labels["level"] == 1][["id", "label"]].rename(
        columns={"id": "cluster-level-1-id", "label": "category_label"}
    )

    # arguments と clusters をマージ（カテゴリ情報付与）
    merged = arguments.merge(clusters[["arg-id", "cluster-level-1-id"]], on="arg-id").merge(
        labels_lv1, on="cluster-level-1-id", how="left"
    )

    # relation_df と結合
    merged = merged.merge(relation_df, on="arg-id", how="left")

    # 元コメント取得
    comments = pd.read_csv(PIPELINE_DIR / f"inputs/{config['input']}.csv")
    comments["comment-id"] = comments["comment-id"].astype(str)
    merged["comment-id"] = merged["comment-id"].astype(str)

    # 元コメント本文などとマージ
    final_df = merged.merge(comments, on="comment-id", how="left")

    # 必要カラムのみ整形
    final_cols = ["comment-id", "comment-body", "arg-id", "argument", "cluster-level-1-id", "category_label"]

    # 基本カラム
    for col in ["x", "y", "source", "url"]:
        if col in comments.columns:
            final_cols.append(col)

    # 属性カラムを追加
    attribute_columns = []
    for col in comments.columns:
        # attributeプレフィックスが付いたカラムを探す
        if col.startswith("attribute_"):
            attribute_columns.append(col)
            final_cols.append(col)

    print(f"属性カラム検出: {attribute_columns}")

    # 必要なカラムだけ選択
    final_df = final_df[final_cols]
    final_df = final_df.rename(
        columns={
            "cluster-level-1-id": "category_id",
            "category_label": "category",
            "arg-id": "arg_id",
            "argument": "argument",
            "comment-body": "original-comment",
        }
    )

    # 保存
    final_df.to_csv(PIPELINE_DIR / f"outputs/{config['output_dir']}/final_result_with_comments.csv", index=False)


def _build_arguments(
    clusters: pd.DataFrame, comments: pd.DataFrame, relation_df: pd.DataFrame, config: dict
) -> list[Argument]:
    """
    Build the arguments list including attribute information from original comments

    Args:
        clusters: DataFrame containing cluster information for each argument
        comments: DataFrame containing original comments with attribute columns
        relation_df: DataFrame relating arguments to original comments
        config: Configuration dictionary containing enable_source_link setting
    """
    cluster_columns = [col for col in clusters.columns if col.startswith("cluster-level-") and "id" in col]

    # Prepare for merging with original comments to get attributes
    comments_copy = comments.copy()
    comments_copy["comment-id"] = comments_copy["comment-id"].astype(str)

    # Get argument to comment mapping
    arg_comment_map = {}
    if "comment-id" in relation_df.columns:
        relation_df["comment-id"] = relation_df["comment-id"].astype(str)
        arg_comment_map = dict(zip(relation_df["arg-id"], relation_df["comment-id"], strict=False))

    # Find attribute columns in comments dataframe
    attribute_columns = [col for col in comments.columns if col.startswith("attribute_")]
    print(f"属性カラム検出: {attribute_columns}")

    arguments: list[Argument] = []
    for _, row in clusters.iterrows():
        cluster_ids = ["0"]
        for cluster_column in cluster_columns:
            cluster_ids.append(str(row[cluster_column]))  # Convert to string to ensure serializable

        # Create base argument
        argument: Argument = {
            "arg_id": str(row["arg-id"]),  # Convert to string to ensure serializable
            "argument": str(row["argument"]),
            "x": float(row["x"]),  # Convert to native float
            "y": float(row["y"]),  # Convert to native float
            "p": 0,  # NOTE: 一旦全部0でいれる
            "cluster_ids": cluster_ids,
            "attributes": None,
            "url": None,
        }

        # Add attributes and URL if available
        if row["arg-id"] in arg_comment_map:
            comment_id = arg_comment_map[row["arg-id"]]
            comment_rows = comments_copy[comments_copy["comment-id"] == comment_id]

            if not comment_rows.empty:
                comment_row = comment_rows.iloc[0]

                # Add URL if available and enabled
                if config.get("enable_source_link", False) and "url" in comment_row and comment_row["url"] is not None:
                    argument["url"] = str(comment_row["url"])

                # Add attributes if available
                if attribute_columns:
                    attributes = {}
                    for attr_col in attribute_columns:
                        # Remove "attribute_" prefix for cleaner attribute names
                        attr_name = attr_col[len("attribute_") :]
                        # Convert potential numpy types to Python native types
                        attr_value = comment_row.get(attr_col, None)
                        if attr_value is not None:
                            if isinstance(attr_value, np.integer):
                                attr_value = int(attr_value)
                            elif isinstance(attr_value, np.floating):
                                attr_value = float(attr_value)
                            elif isinstance(attr_value, np.ndarray):
                                attr_value = attr_value.tolist()
                        attributes[attr_name] = attr_value

                    # Only add non-empty attributes
                    if any(v is not None for v in attributes.values()):
                        argument["attributes"] = attributes

        arguments.append(argument)
    return arguments


def _build_cluster_value(melted_labels: pd.DataFrame, total_num: int) -> list[Cluster]:
    results: list[Cluster] = [
        Cluster(
            level=0,
            id="0",
            label="全体",
            takeaway="",
            value=int(total_num),  # Convert to native int
            parent="",
            density_rank_percentile=0,
        )
    ]

    for _, melted_label in melted_labels.iterrows():
        # Convert potential NumPy types to native Python types
        level = (
            int(melted_label["level"]) if isinstance(melted_label["level"], int | np.integer) else melted_label["level"]
        )
        cluster_id = str(melted_label["id"])
        label = str(melted_label["label"])
        takeaway = str(melted_label["description"])
        value = (
            int(melted_label["value"]) if isinstance(melted_label["value"], int | np.integer) else melted_label["value"]
        )
        parent = str(melted_label.get("parent", "全体"))

        # Handle density_rank_percentile which might be None or a numeric value
        density_rank = melted_label.get("density_rank_percentile")
        if density_rank is not None:
            if isinstance(density_rank, float | np.floating):
                density_rank = float(density_rank)
            elif isinstance(density_rank, int | np.integer):
                density_rank = int(density_rank)

        cluster_value = Cluster(
            level=level,
            id=cluster_id,
            label=label,
            takeaway=takeaway,
            value=value,
            parent=parent,
            density_rank_percentile=density_rank,
        )
        results.append(cluster_value)
    return results


def _build_comments_value(
    comments: pd.DataFrame,
    arguments: pd.DataFrame,
    hidden_properties_map: dict[str, list[str]],
):
    comment_dict: dict[str, dict[str, str]] = {}
    useful_comment_ids = set(arguments["comment-id"].values)
    for _, row in comments.iterrows():
        id = row["comment-id"]
        if id in useful_comment_ids:
            res = {"comment": row["comment-body"]}
            should_skip = any(row[prop] in hidden_values for prop, hidden_values in hidden_properties_map.items())
            if should_skip:
                continue
            comment_dict[str(id)] = res

    return comment_dict


def _build_translations(config):
    languages = list(config.get("translation", {}).get("languages", []))
    if len(languages) > 0:
        with open(PIPELINE_DIR / f"outputs/{config['output_dir']}/translations.json") as f:
            translations = f.read()
        return json.loads(translations)
    return {}


def _build_property_map(
    arguments: pd.DataFrame, comments: pd.DataFrame, hidden_properties_map: dict[str, list[str]], config: dict
) -> dict[str, dict[str, str]]:
    property_columns = list(hidden_properties_map.keys()) + list(config["extraction"]["categories"].keys())
    property_map = defaultdict(dict)

    # 指定された property_columns が arguments に存在するかチェック
    missing_cols = [col for col in property_columns if col not in arguments.columns]
    if missing_cols:
        raise ValueError(
            f"指定されたカラム {missing_cols} が args.csv に存在しません。"
            "設定ファイルaggregation / hidden_propertiesから該当カラムを取り除いてください。"
        )

    for prop in property_columns:
        for arg_id, row in arguments.iterrows():
            # LLMによるcategory classificationがうまく行かず、NaNの場合はNoneにする
            value = row[prop] if not pd.isna(row[prop]) else None

            # Convert NumPy types to Python native types
            if value is not None:
                if isinstance(value, np.integer):
                    value = int(value)
                elif isinstance(value, np.floating):
                    value = float(value)
                elif isinstance(value, np.ndarray):
                    value = value.tolist()
                else:
                    # Convert any other types to string to ensure serialization
                    try:
                        value = str(value)
                    except Exception as e:
                        print(f"Error converting value to string: {e}")
                        value = None

            # Make sure arg_id is string
            str_arg_id = str(arg_id)
            property_map[prop][str_arg_id] = value

    return property_map
1f:T458,import os

import pandas as pd
from tqdm import tqdm

from services.llm import request_to_embed


def embedding(config):
    model = config["embedding"]["model"]
    is_embedded_at_local = config["is_embedded_at_local"]
    # print("start embedding")
    # print(f"embedding model: {model}, is_embedded_at_local: {is_embedded_at_local}")

    dataset = config["output_dir"]
    path = f"outputs/{dataset}/embeddings.pkl"
    arguments = pd.read_csv(f"outputs/{dataset}/args.csv", usecols=["arg-id", "argument"])
    embeddings = []
    batch_size = 1000
    for i in tqdm(range(0, len(arguments), batch_size)):
        args = arguments["argument"].tolist()[i : i + batch_size]
        embeds = request_to_embed(
            args,
            model,
            is_embedded_at_local,
            config["provider"],
            local_llm_address=config.get("local_llm_address"),
            user_api_key=os.getenv("USER_API_KEY"),
        )
        embeddings.extend(embeds)
    df = pd.DataFrame([{"arg-id": arguments.iloc[i]["arg-id"], "embedding": e} for i, e in enumerate(embeddings)])
    df.to_pickle(path)
20:T194c,import concurrent.futures
import json
import logging
import os
import re

import pandas as pd
from pydantic import BaseModel, Field
from tqdm import tqdm

from services.llm import request_to_chat_ai
from services.parse_json_list import parse_extraction_response
from utils import update_progress

COMMA_AND_SPACE_AND_RIGHT_BRACKET = re.compile(r",\s*(\])")


class ExtractionResponse(BaseModel):
    extractedOpinionList: list[str] = Field(..., description="抽出した意見のリスト")


def _validate_property_columns(property_columns: list[str], comments: pd.DataFrame) -> None:
    if not all(property in comments.columns for property in property_columns):
        raise ValueError(f"Properties {property_columns} not found in comments. Columns are {comments.columns}")


def extraction(config):
    dataset = config["output_dir"]
    path = f"outputs/{dataset}/args.csv"
    model = config["extraction"]["model"]
    prompt = config["extraction"]["prompt"]
    workers = config["extraction"]["workers"]
    limit = config["extraction"]["limit"]
    property_columns = config["extraction"]["properties"]

    if "provider" not in config:
        raise RuntimeError("provider is not set")
    provider = config["provider"]

    # カラム名だけを読み込み、必要なカラムが含まれているか確認する
    comments = pd.read_csv(f"inputs/{config['input']}.csv", nrows=0)
    _validate_property_columns(property_columns, comments)
    # エラーが出なかった場合、すべての行を読み込む
    comments = pd.read_csv(
        f"inputs/{config['input']}.csv", usecols=["comment-id", "comment-body"] + config["extraction"]["properties"]
    )
    comment_ids = (comments["comment-id"].values)[:limit]
    comments.set_index("comment-id", inplace=True)
    results = pd.DataFrame()
    update_progress(config, total=len(comment_ids))

    argument_map = {}
    relation_rows = []

    for i in tqdm(range(0, len(comment_ids), workers)):
        batch = comment_ids[i : i + workers]
        batch_inputs = [comments.loc[id]["comment-body"] for id in batch]
        batch_results = extract_batch(
            batch_inputs, prompt, model, workers, provider, config.get("local_llm_address"), config
        )

        for comment_id, extracted_args in zip(batch, batch_results, strict=False):
            for j, arg in enumerate(extracted_args):
                if arg not in argument_map:
                    # argumentテーブルに追加
                    arg_id = f"A{comment_id}_{j}"
                    argument = arg
                    argument_map[arg] = {
                        "arg-id": arg_id,
                        "argument": argument,
                    }
                else:
                    arg_id = argument_map[arg]["arg-id"]

                # relationテーブルにcommentとargの関係を追加
                relation_row = {
                    "arg-id": arg_id,
                    "comment-id": comment_id,
                }
                relation_rows.append(relation_row)

        update_progress(config, incr=len(batch))

    # DataFrame化
    results = pd.DataFrame(argument_map.values())
    relation_df = pd.DataFrame(relation_rows)

    if results.empty:
        raise RuntimeError("result is empty, maybe bad prompt")

    results.to_csv(path, index=False)
    # comment-idとarg-idの関係を保存
    relation_df.to_csv(f"outputs/{dataset}/relations.csv", index=False)


logging.basicConfig(level=logging.DEBUG)


def extract_batch(batch, prompt, model, workers, provider="openai", local_llm_address=None, config=None):
    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:
        futures_with_index = [
            (i, executor.submit(extract_arguments, input, prompt, model, provider, local_llm_address))
            for i, input in enumerate(batch)
        ]

        done, not_done = concurrent.futures.wait([f for _, f in futures_with_index], timeout=30)
        results = [[] for _ in range(len(batch))]
        total_token_input = 0
        total_token_output = 0
        total_token_usage = 0

        for _, future in futures_with_index:
            if future in not_done and not future.cancelled():
                future.cancel()

        for i, future in futures_with_index:
            if future in done:
                try:
                    result = future.result()
                    if isinstance(result, tuple) and len(result) == 4:
                        items, token_input, token_output, token_total = result
                        results[i] = items
                        total_token_input += token_input
                        total_token_output += token_output
                        total_token_usage += token_total
                    else:
                        results[i] = result
                except Exception as e:
                    logging.error(f"Task {future} failed with error: {e}")
                    results[i] = []

        if config is not None:
            config["total_token_usage"] = config.get("total_token_usage", 0) + total_token_usage
            config["token_usage_input"] = config.get("token_usage_input", 0) + total_token_input
            config["token_usage_output"] = config.get("token_usage_output", 0) + total_token_output
            print(
                f"Extraction batch: input={total_token_input}, output={total_token_output}, total={total_token_usage} tokens"
            )

        return results


def extract_arguments(input, prompt, model, provider="openai", local_llm_address=None):
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": input},
    ]
    try:
        response, token_input, token_output, token_total = request_to_chat_ai(
            messages=messages,
            model=model,
            is_json=False,
            json_schema=ExtractionResponse,
            provider=provider,
            local_llm_address=local_llm_address,
            user_api_key=os.getenv("USER_API_KEY"),
        )
        items = parse_extraction_response(response)
        items = list(filter(None, items))  # omit empty strings
        return items, token_input, token_output, token_total
    except json.decoder.JSONDecodeError as e:
        print("JSON error:", e)
        print("Input was:", input)
        print("Response was:", response)
        print("Silently giving up on trying to generate valid list.")
        return []
21:T458,import os

import pandas as pd
from tqdm import tqdm

from services.llm import request_to_embed


def embedding(config):
    model = config["embedding"]["model"]
    is_embedded_at_local = config["is_embedded_at_local"]
    # print("start embedding")
    # print(f"embedding model: {model}, is_embedded_at_local: {is_embedded_at_local}")

    dataset = config["output_dir"]
    path = f"outputs/{dataset}/embeddings.pkl"
    arguments = pd.read_csv(f"outputs/{dataset}/args.csv", usecols=["arg-id", "argument"])
    embeddings = []
    batch_size = 1000
    for i in tqdm(range(0, len(arguments), batch_size)):
        args = arguments["argument"].tolist()[i : i + batch_size]
        embeds = request_to_embed(
            args,
            model,
            is_embedded_at_local,
            config["provider"],
            local_llm_address=config.get("local_llm_address"),
            user_api_key=os.getenv("USER_API_KEY"),
        )
        embeddings.extend(embeds)
    df = pd.DataFrame([{"arg-id": arguments.iloc[i]["arg-id"], "embedding": e} for i, e in enumerate(embeddings)])
    df.to_pickle(path)
22:T1149,"""Cluster the arguments using UMAP + HDBSCAN and GPT-4."""

from importlib import import_module

import numpy as np
import pandas as pd
import scipy.cluster.hierarchy as sch
from sklearn.cluster import KMeans


def hierarchical_clustering(config):
    UMAP = import_module("umap").UMAP

    dataset = config["output_dir"]
    path = f"outputs/{dataset}/hierarchical_clusters.csv"
    arguments_df = pd.read_csv(f"outputs/{dataset}/args.csv", usecols=["arg-id", "argument"])
    embeddings_df = pd.read_pickle(f"outputs/{dataset}/embeddings.pkl")
    embeddings_array = np.asarray(embeddings_df["embedding"].values.tolist())
    cluster_nums = config["hierarchical_clustering"]["cluster_nums"]

    n_samples = embeddings_array.shape[0]
    # デフォルト設定は15
    default_n_neighbors = 15

    # テスト等サンプルが少なすぎる場合、n_neighborsの設定値を下げる
    if n_samples <= default_n_neighbors:
        n_neighbors = max(2, n_samples - 1)  # 最低2以上
    else:
        n_neighbors = default_n_neighbors

    umap_model = UMAP(random_state=42, n_components=2, n_neighbors=n_neighbors)
    # TODO 詳細エラーメッセージを加える
    # 以下のエラーの場合、おそらく元の意見件数が少なすぎることが原因
    # TypeError: Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.
    umap_embeds = umap_model.fit_transform(embeddings_array)

    cluster_results = hierarchical_clustering_embeddings(
        umap_embeds=umap_embeds,
        cluster_nums=cluster_nums,
    )
    result_df = pd.DataFrame(
        {
            "arg-id": arguments_df["arg-id"],
            "argument": arguments_df["argument"],
            "x": umap_embeds[:, 0],
            "y": umap_embeds[:, 1],
        }
    )

    for cluster_level, final_labels in enumerate(cluster_results.values(), start=1):
        result_df[f"cluster-level-{cluster_level}-id"] = [f"{cluster_level}_{label}" for label in final_labels]

    result_df.to_csv(path, index=False)


def generate_cluster_count_list(min_clusters: int, max_clusters: int):
    cluster_counts = []
    current = min_clusters
    cluster_counts.append(current)

    if min_clusters == max_clusters:
        return cluster_counts

    while True:
        next_double = current * 2
        next_triple = current * 3

        if next_double >= max_clusters:
            if cluster_counts[-1] != max_clusters:
                cluster_counts.append(max_clusters)
            break

        # 次の倍はまだ max_clusters に収まるが、3倍だと超える
        # -> (次の倍は細かすぎるので)スキップして max_clusters に飛ぶ
        if next_triple > max_clusters:
            cluster_counts.append(max_clusters)
            break

        cluster_counts.append(next_double)
        current = next_double

    return cluster_counts


def merge_clusters_with_hierarchy(
    cluster_centers: np.ndarray,
    kmeans_labels: np.ndarray,
    umap_array: np.ndarray,
    n_cluster_cut: int,
):
    Z = sch.linkage(cluster_centers, method="ward")
    cluster_labels_merged = sch.fcluster(Z, t=n_cluster_cut, criterion="maxclust")

    n_samples = umap_array.shape[0]
    final_labels = np.zeros(n_samples, dtype=int)

    for i in range(n_samples):
        original_label = kmeans_labels[i]
        final_labels[i] = cluster_labels_merged[original_label]

    return final_labels


def hierarchical_clustering_embeddings(
    umap_embeds,
    cluster_nums,
):
    # 最大分割数でクラスタリングを実施
    print("start initial clustering")
    initial_cluster_num = cluster_nums[-1]
    kmeans_model = KMeans(n_clusters=initial_cluster_num, random_state=42)
    kmeans_model.fit(umap_embeds)
    print("end initial clustering")

    results = {}
    print("start hierarchical clustering")
    cluster_nums.sort()
    print(cluster_nums)
    for n_cluster_cut in cluster_nums[:-1]:
        print("n_cluster_cut: ", n_cluster_cut)
        final_labels = merge_clusters_with_hierarchy(
            cluster_centers=kmeans_model.cluster_centers_,
            kmeans_labels=kmeans_model.labels_,
            umap_array=umap_embeds,
            n_cluster_cut=n_cluster_cut,
        )
        results[n_cluster_cut] = final_labels

    results[initial_cluster_num] = kmeans_model.labels_
    print("end hierarchical clustering")

    return results
23:T1c36,import json
import os
from concurrent.futures import ThreadPoolExecutor
from functools import partial
from typing import TypedDict

import pandas as pd
from pydantic import BaseModel, Field

from services.llm import request_to_chat_ai


class LabellingResult(TypedDict):
    """各クラスタのラベリング結果を表す型"""

    cluster_id: str  # クラスタのID
    label: str  # クラスタのラベル名
    description: str  # クラスタの説明文


def hierarchical_initial_labelling(config: dict) -> None:
    """階層的クラスタリングの初期ラベリングを実行する

    Args:
        config: 設定情報を含む辞書
            - output_dir: 出力ディレクトリ名
            - hierarchical_initial_labelling: 初期ラベリングの設定
                - sampling_num: サンプリング数
                - prompt: LLMへのプロンプト
                - model: 使用するLLMモデル名
                - workers: 並列処理のワーカー数
            - provider: LLMプロバイダー
    """
    dataset = config["output_dir"]
    path = f"outputs/{dataset}/hierarchical_initial_labels.csv"
    clusters_argument_df = pd.read_csv(f"outputs/{dataset}/hierarchical_clusters.csv")

    cluster_id_columns = [col for col in clusters_argument_df.columns if col.startswith("cluster-level-")]
    initial_cluster_id_column = cluster_id_columns[-1]
    sampling_num = config["hierarchical_initial_labelling"]["sampling_num"]
    initial_labelling_prompt = config["hierarchical_initial_labelling"]["prompt"]
    model = config["hierarchical_initial_labelling"]["model"]
    workers = config["hierarchical_initial_labelling"]["workers"]

    # トークン使用量を追跡するための変数を初期化
    config["total_token_usage"] = config.get("total_token_usage", 0)

    initial_label_df = initial_labelling(
        initial_labelling_prompt,
        clusters_argument_df,
        sampling_num,
        model,
        workers,
        config["provider"],
        config.get("local_llm_address"),
        config,  # configを渡して、トークン使用量を累積できるようにする
    )
    print("start initial labelling")
    initial_clusters_argument_df = clusters_argument_df.merge(
        initial_label_df,
        left_on=initial_cluster_id_column,
        right_on="cluster_id",
        how="left",
    ).rename(
        columns={
            "label": f"{initial_cluster_id_column.replace('-id', '')}-label",
            "description": f"{initial_cluster_id_column.replace('-id', '')}-description",
        }
    )
    print("end initial labelling")
    initial_clusters_argument_df.to_csv(path, index=False)


def initial_labelling(
    prompt: str,
    clusters_df: pd.DataFrame,
    sampling_num: int,
    model: str,
    workers: int,
    provider: str = "openai",
    local_llm_address: str | None = None,
    config: dict | None = None,  # configを追加
) -> pd.DataFrame:
    """各クラスタに対して初期ラベリングを実行する

    Args:
        prompt: LLMへのプロンプト
        clusters_df: クラスタリング結果のDataFrame
        sampling_num: 各クラスタからサンプリングする意見の数
        model: 使用するLLMモデル名
        workers: 並列処理のワーカー数
        provider: LLMプロバイダー
        local_llm_address: ローカルLLMのアドレス
        config: 設定情報を含む辞書（トークン使用量の累積に使用）

    Returns:
        各クラスタのラベリング結果を含むDataFrame
    """
    cluster_columns = [col for col in clusters_df.columns if col.startswith("cluster-level-")]
    initial_cluster_column = cluster_columns[-1]
    cluster_ids = clusters_df[initial_cluster_column].unique()
    process_func = partial(
        process_initial_labelling,
        df=clusters_df,
        prompt=prompt,
        sampling_num=sampling_num,
        target_column=initial_cluster_column,
        model=model,
        provider=provider,
        local_llm_address=local_llm_address,
        config=config,  # configを渡す
    )
    with ThreadPoolExecutor(max_workers=workers) as executor:
        results = list(executor.map(process_func, cluster_ids))
    return pd.DataFrame(results)


class LabellingFromat(BaseModel):
    """ラベリング結果のフォーマットを定義する"""

    label: str = Field(..., description="クラスタのラベル名")
    description: str = Field(..., description="クラスタの説明文")


def process_initial_labelling(
    cluster_id: str,
    df: pd.DataFrame,
    prompt: str,
    sampling_num: int,
    target_column: str,
    model: str,
    provider: str = "openai",
    local_llm_address: str | None = None,
    config: dict | None = None,  # configを追加
) -> LabellingResult:
    """個別のクラスタに対してラベリングを実行する

    Args:
        cluster_id: 処理対象のクラスタID
        df: クラスタリング結果のDataFrame
        prompt: LLMへのプロンプト
        sampling_num: サンプリングする意見の数
        target_column: クラスタIDが格納されている列名
        model: 使用するLLMモデル名
        provider: LLMプロバイダー
        local_llm_address: ローカルLLMのアドレス
        config: 設定情報を含む辞書（トークン使用量の累積に使用）

    Returns:
        クラスタのラベリング結果
    """
    cluster_data = df[df[target_column] == cluster_id]
    sampling_num = min(sampling_num, len(cluster_data))
    cluster = cluster_data.sample(sampling_num)
    input = "\n".join(cluster["argument"].values)
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": input},
    ]
    try:
        response_text, token_input, token_output, token_total = request_to_chat_ai(
            messages=messages,
            model=model,
            provider=provider,
            json_schema=LabellingFromat,
            local_llm_address=local_llm_address,
            user_api_key=os.getenv("USER_API_KEY"),
        )

        # トークン使用量を累積（configが渡されている場合）
        if config is not None:
            config["total_token_usage"] = config.get("total_token_usage", 0) + token_total
            config["token_usage_input"] = config.get("token_usage_input", 0) + token_input
            config["token_usage_output"] = config.get("token_usage_output", 0) + token_output

        response_json = json.loads(response_text) if isinstance(response_text, str) else response_text
        return LabellingResult(
            cluster_id=cluster_id,
            label=response_json.get("label", "エラーでラベル名が取得できませんでした"),
            description=response_json.get("description", "エラーで解説が取得できませんでした"),
        )
    except Exception as e:
        print(e)
        return LabellingResult(
            cluster_id=cluster_id,
            label="エラーでラベル名が取得できませんでした",
            description="エラーで解説が取得できませんでした",
        )
24:T337b,import json
import os
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from functools import partial

import numpy as np
import pandas as pd
from pydantic import BaseModel, Field
from tqdm import tqdm

from services.llm import request_to_chat_ai


@dataclass
class ClusterColumns:
    """同一階層のクラスター関連のカラム名を管理するクラス"""

    id: str
    label: str
    description: str

    @classmethod
    def from_id_column(cls, id_column: str) -> "ClusterColumns":
        """ID列名から関連するカラム名を生成"""
        return cls(
            id=id_column,
            label=id_column.replace("-id", "-label"),
            description=id_column.replace("-id", "-description"),
        )


@dataclass
class ClusterValues:
    """対象クラスタのlabel/descriptionを管理するクラス"""

    label: str
    description: str

    def to_prompt_text(self) -> str:
        return f"- {self.label}: {self.description}"


def hierarchical_merge_labelling(config: dict) -> None:
    """階層的クラスタリングの結果に対してマージラベリングを実行する

    Args:
        config: 設定情報を含む辞書
            - output_dir: 出力ディレクトリ名
            - hierarchical_merge_labelling: マージラベリングの設定
                - sampling_num: サンプリング数
                - prompt: LLMへのプロンプト
                - model: 使用するLLMモデル名
                - workers: 並列処理のワーカー数
            - provider: LLMプロバイダー
    """
    dataset = config["output_dir"]
    merge_path = f"outputs/{dataset}/hierarchical_merge_labels.csv"
    clusters_df = pd.read_csv(f"outputs/{dataset}/hierarchical_initial_labels.csv")

    cluster_id_columns: list[str] = _filter_id_columns(clusters_df.columns)
    # ボトムクラスタのラベル・説明とクラスタid付きの各argumentを入力し、各階層のクラスタラベル・説明を生成し、argumentに付けたdfを作成
    merge_result_df = merge_labelling(
        clusters_df=clusters_df,
        cluster_id_columns=sorted(cluster_id_columns, reverse=True),
        config=config,
    )
    # 上記のdfから各クラスタのlevel, id, label, description, valueを取得してdfを作成
    melted_df = melt_cluster_data(merge_result_df)
    # 上記のdfに親子関係を追加
    parent_child_df = _build_parent_child_mapping(merge_result_df, cluster_id_columns)
    melted_df = melted_df.merge(parent_child_df, on=["level", "id"], how="left")
    density_df = calculate_cluster_density(melted_df, config)
    density_df.to_csv(merge_path, index=False)


def _build_parent_child_mapping(df: pd.DataFrame, cluster_id_columns: list[str]):
    """クラスタ間の親子関係をマッピングする

    Args:
        df: クラスタリング結果のDataFrame
        cluster_id_columns: クラスタIDのカラム名のリスト

    Returns:
        親子関係のマッピング情報を含むDataFrame
    """
    results = []
    top_cluster_column = cluster_id_columns[0]
    top_cluster_values = df[top_cluster_column].unique()
    for c in top_cluster_values:
        results.append(
            {
                "level": 1,
                "id": c,
                "parent": "0",  # aggregationで追加する全体クラスタのid
            }
        )

    for idx in range(len(cluster_id_columns) - 1):
        current_column = cluster_id_columns[idx]
        children_column = cluster_id_columns[idx + 1]
        current_level = current_column.replace("-id", "").replace("cluster-level-", "")
        # 現在のレベルのクラスタid
        current_cluster_values = df[current_column].unique()
        for current_id in current_cluster_values:
            children_ids = df.loc[df[current_column] == current_id, children_column].unique()
            for child_id in children_ids:
                results.append(
                    {
                        "level": int(current_level) + 1,
                        "id": child_id,
                        "parent": current_id,
                    }
                )
    return pd.DataFrame(results)


def _filter_id_columns(columns: list[str]) -> list[str]:
    """クラスタIDのカラム名をフィルタリングする

    Args:
        columns: 全カラム名のリスト

    Returns:
        クラスタIDのカラム名のリスト
    """
    return [col for col in columns if col.startswith("cluster-level-") and col.endswith("-id")]


def melt_cluster_data(df: pd.DataFrame) -> pd.DataFrame:
    """クラスタデータを行形式に変換する

    cluster-level-n-(id|label|description) を行形式 (level, id, label, description, value) にまとめる。
    [cluster-level-n-id, cluster-level-n-label, cluster-level-n-description] を [level, id, label, description, value(件数)] に変換する。

    Args:
        df: クラスタリング結果のDataFrame

    Returns:
        行形式に変換されたDataFrame
    """
    id_columns: list[str] = _filter_id_columns(df.columns)
    levels: set[int] = {int(col.replace("cluster-level-", "").replace("-id", "")) for col in id_columns}
    all_rows: list[dict] = []

    # levelごとに各クラスタの出現件数を集計・縦持ちにする
    for level in levels:
        cluster_columns = ClusterColumns.from_id_column(f"cluster-level-{level}-id")
        # クラスタidごとの件数集計
        level_count_df = df.groupby(cluster_columns.id).size().reset_index(name="value")

        level_unique_val_df = df[
            [cluster_columns.id, cluster_columns.label, cluster_columns.description]
        ].drop_duplicates()
        level_unique_val_df = level_unique_val_df.merge(level_count_df, on=cluster_columns.id, how="left")
        level_unique_vals = [
            {
                "level": level,
                "id": row[cluster_columns.id],
                "label": row[cluster_columns.label],
                "description": row[cluster_columns.description],
                "value": row["value"],
            }
            for _, row in level_unique_val_df.iterrows()
        ]
        all_rows.extend(level_unique_vals)
    return pd.DataFrame(all_rows)


def merge_labelling(clusters_df: pd.DataFrame, cluster_id_columns: list[str], config) -> pd.DataFrame:
    """階層的なクラスタのマージラベリングを実行する

    Args:
        clusters_df: クラスタリング結果のDataFrame
        cluster_id_columns: クラスタIDのカラム名のリスト
        config: 設定情報を含む辞書

    Returns:
        マージラベリング結果を含むDataFrame
    """
    for idx in tqdm(range(len(cluster_id_columns) - 1)):
        previous_columns = ClusterColumns.from_id_column(cluster_id_columns[idx])
        current_columns = ClusterColumns.from_id_column(cluster_id_columns[idx + 1])

        process_fn = partial(
            process_merge_labelling,
            result_df=clusters_df,
            current_columns=current_columns,
            previous_columns=previous_columns,
            config=config,
        )

        current_cluster_ids = sorted(clusters_df[current_columns.id].unique())
        with ThreadPoolExecutor(max_workers=config["hierarchical_merge_labelling"]["workers"]) as executor:
            responses = list(
                tqdm(
                    executor.map(process_fn, current_cluster_ids),
                    total=len(current_cluster_ids),
                )
            )

        current_result_df = pd.DataFrame(responses)
        clusters_df = clusters_df.merge(current_result_df, on=[current_columns.id])
    return clusters_df


class LabellingFromat(BaseModel):
    """ラベリング結果のフォーマットを定義する"""

    label: str = Field(..., description="クラスタのラベル名")
    description: str = Field(..., description="クラスタの説明文")


def process_merge_labelling(
    target_cluster_id: str,
    result_df: pd.DataFrame,
    current_columns: ClusterColumns,
    previous_columns: ClusterColumns,
    config,
):
    """個別のクラスタに対してマージラベリングを実行する

    Args:
        target_cluster_id: 処理対象のクラスタID
        result_df: クラスタリング結果のDataFrame
        current_columns: 現在のレベルのカラム情報
        previous_columns: 前のレベルのカラム情報
        config: 設定情報を含む辞書

    Returns:
        マージラベリング結果を含む辞書
    """

    def filter_previous_values(df: pd.DataFrame, previous_columns: ClusterColumns) -> list[ClusterValues]:
        """前のレベルのクラスタ情報を取得する"""
        previous_records = df[df[current_columns.id] == target_cluster_id][
            [previous_columns.label, previous_columns.description]
        ].drop_duplicates()
        previous_values = [
            ClusterValues(
                label=row[previous_columns.label],
                description=row[previous_columns.description],
            )
            for _, row in previous_records.iterrows()
        ]
        return previous_values

    previous_values = filter_previous_values(result_df, previous_columns)
    if len(previous_values) == 1:
        return {
            current_columns.id: target_cluster_id,
            current_columns.label: previous_values[0].label,
            current_columns.description: previous_values[0].description,
        }
    elif len(previous_values) == 0:
        raise ValueError(f"クラスタ {target_cluster_id} には前のレベルのクラスタが存在しません。")

    current_cluster_data = result_df[result_df[current_columns.id] == target_cluster_id]
    sampling_num = min(
        config["hierarchical_merge_labelling"]["sampling_num"],
        len(current_cluster_data),
    )
    sampled_data = current_cluster_data.sample(sampling_num)
    sampled_argument_text = "\n".join(sampled_data["argument"].values)
    cluster_text = "\n".join([value.to_prompt_text() for value in previous_values])
    messages = [
        {"role": "system", "content": config["hierarchical_merge_labelling"]["prompt"]},
        {
            "role": "user",
            "content": "クラスタラベル\n" + cluster_text + "\n" + "クラスタの意見\n" + sampled_argument_text,
        },
    ]
    try:
        response_text, token_input, token_output, token_total = request_to_chat_ai(
            messages=messages,
            model=config["hierarchical_merge_labelling"]["model"],
            json_schema=LabellingFromat,
            provider=config["provider"],
            local_llm_address=config.get("local_llm_address"),
            user_api_key=os.getenv("USER_API_KEY"),
        )

        config["total_token_usage"] = config.get("total_token_usage", 0) + token_total
        config["token_usage_input"] = config.get("token_usage_input", 0) + token_input
        config["token_usage_output"] = config.get("token_usage_output", 0) + token_output
        print(f"Merge labelling: input={token_input}, output={token_output}, total={token_total} tokens")

        response_json = json.loads(response_text) if isinstance(response_text, str) else response_text
        return {
            current_columns.id: target_cluster_id,
            current_columns.label: response_json.get("label", "エラーでラベル名が取得できませんでした"),
            current_columns.description: response_json.get("description", "エラーで解説が取得できませんでした"),
        }
    except Exception as e:
        print(f"エラーが発生しました: {e}")
        return {
            current_columns.id: target_cluster_id,
            current_columns.label: "エラーでラベル名が取得できませんでした",
            current_columns.description: "エラーで解説が取得できませんでした",
        }


def calculate_cluster_density(melted_df: pd.DataFrame, config: dict):
    """クラスタ内の密度計算"""
    hierarchical_cluster_df = pd.read_csv(f"outputs/{config['output_dir']}/hierarchical_clusters.csv")

    densities = []
    for level, c_id in zip(melted_df["level"], melted_df["id"], strict=False):
        cluster_embeds = hierarchical_cluster_df[hierarchical_cluster_df[f"cluster-level-{level}-id"] == c_id][
            ["x", "y"]
        ].values
        density = calculate_density(cluster_embeds)
        densities.append(density)

    # 密度のランクを計算
    melted_df["density"] = densities
    melted_df["density_rank"] = melted_df.groupby("level")["density"].rank(ascending=False, method="first")
    melted_df["density_rank_percentile"] = melted_df.groupby("level")["density_rank"].transform(lambda x: x / len(x))
    return melted_df


def calculate_density(embeds: np.ndarray):
    """平均距離に基づいて密度を計算"""
    center = np.mean(embeds, axis=0)
    distances = np.linalg.norm(embeds - center, axis=1)
    avg_distance = np.mean(distances)
    density = 1 / (avg_distance + 1e-10)
    return density
25:Ta82,"""Create summaries for the clusters."""

import json
import os
import re

import pandas as pd
from pydantic import BaseModel, Field

from services.llm import request_to_chat_ai


class OverviewResponse(BaseModel):
    summary: str = Field(..., description="クラスターの全体的な要約")


def hierarchical_overview(config):
    dataset = config["output_dir"]
    path = f"outputs/{dataset}/hierarchical_overview.txt"

    hierarchical_label_df = pd.read_csv(f"outputs/{dataset}/hierarchical_merge_labels.csv")

    prompt = config["hierarchical_overview"]["prompt"]
    model = config["hierarchical_overview"]["model"]

    # TODO: level1で固定にしているが、設定で変えられるようにする
    target_level = 1
    target_records = hierarchical_label_df[hierarchical_label_df["level"] == target_level]
    ids = target_records["id"].to_list()
    labels = target_records["label"].to_list()
    descriptions = target_records["description"].to_list()
    target_records.set_index("id", inplace=True)

    input_text = ""
    for i, _ in enumerate(ids):
        input_text += f"# Cluster {i}/{len(ids)}: {labels[i]}\n\n"
        input_text += descriptions[i] + "\n\n"

    messages = [{"role": "system", "content": prompt}, {"role": "user", "content": input_text}]
    response_text, token_input, token_output, token_total = request_to_chat_ai(
        messages=messages,
        model=model,
        provider=config["provider"],
        local_llm_address=config.get("local_llm_address"),
        user_api_key=os.getenv("USER_API_KEY"),
        json_schema=OverviewResponse,
    )

    # トークン使用量を累積
    config["total_token_usage"] = config.get("total_token_usage", 0) + token_total
    config["token_usage_input"] = config.get("token_usage_input", 0) + token_input
    config["token_usage_output"] = config.get("token_usage_output", 0) + token_output
    print(f"Hierarchical overview: input={token_input}, output={token_output}, total={token_total} tokens")

    try:
        # structured outputとしてパースできるなら処理する
        if isinstance(response_text, dict):
            parsed_response = response_text
        else:
            parsed_response = json.loads(response_text)

        with open(path, "w") as file:
            file.write(parsed_response["summary"])

    except Exception:
        # thinkタグが出力されるReasoningモデル用に、thinkタグを除去する
        thinking_removed = re.sub(
            r"<think\b[^>]*>.*?</think>",
            "",
            response_text,
            flags=re.DOTALL,
        )

        with open(path, "w") as file:
            file.write(thinking_removed)
8:[["$","$L13",null,{}],["$","$L14",null,{"className":"container","mt":"8","children":[["$","$L14",null,{"mx":"auto","maxW":"750px","mb":8,"children":[["$","$L15",null,{"textAlign":"left","fontSize":"xl","mb":5,"children":"レポート"}],["$","$L15",null,{"as":"h2","size":"4xl","mb":2,"className":"headingColor","children":"②自分が市長なら、2040年に向けてこんな課題に取り組む【2/15 15:00 更新】"}],["$","$L16",null,{"fontWeight":"bold","fontSize":"xl","mb":2,"children":[["$","$L17",null,{"mr":1,"children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":20,"height":20,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-messages-square","children":[["$","path","p1xzt8",{"d":"M14 9a2 2 0 0 1-2 2H6l-4 4V4a2 2 0 0 1 2-2h8a2 2 0 0 1 2 2z"}],["$","path","1cx29u",{"d":"M18 9h2a2 2 0 0 1 2 2v11l-4-4h-6a2 2 0 0 1-2-2v-1"}],"$undefined"]}]}],"212","件"]}],["$","p",null,{"children":"舞鶴市の地域活性化に向けた意見は、観光資源の活用や地域経済の振興、子育て支援、交通インフラの整備など多岐にわたります。特に、観光施設の充実や地元産業の支援、医療介護の充実が重要視されており、地域の魅力向上が期待されています。また、教育環境の改善や世代間交流の促進、人口減少対策も重要なテーマとして挙げられています。これらの取り組みを通じて、持続可能で住みやすい地域社会の実現が目指されています。"}]]}],["$","$L18",null,{"result":{"arguments":[{"arg_id":"Acsv-1_0","argument":"赤レンガを中心とした観光業を推進すべき","x":6.3060937,"y":5.9965286,"p":0,"cluster_ids":["0","1_8","2_29"],"attributes":null,"url":null},{"arg_id":"Acsv-1_1","argument":"大型商業施設やアウトレットの誘致が必要","x":6.5711727,"y":7.5207953,"p":0,"cluster_ids":["0","1_7","2_57"],"attributes":null,"url":null},{"arg_id":"Acsv-1_2","argument":"子育て世帯が暮らしやすいように給食や医療の無償化を行うべき","x":2.5335276,"y":7.9539175,"p":0,"cluster_ids":["0","1_2","2_17"],"attributes":null,"url":null},{"arg_id":"Acsv-1_3","argument":"子ども世帯にお金の給付を行うべき","x":2.5105019,"y":7.673093,"p":0,"cluster_ids":["0","1_2","2_17"],"attributes":null,"url":null},{"arg_id":"Acsv-1_4","argument":"舞鶴にしかない魅力的なお菓子を活用すべき","x":7.98267,"y":5.9259577,"p":0,"cluster_ids":["0","1_8","2_6"],"attributes":null,"url":null},{"arg_id":"Acsv-1_5","argument":"バイパス道路の整備を行い渋滞を解消すべき","x":5.3288713,"y":4.038846,"p":0,"cluster_ids":["0","1_6","2_43"],"attributes":null,"url":null},{"arg_id":"Acsv-1_6","argument":"病院を1つに統合し専門医療を充実させるべき","x":3.0799048,"y":6.840655,"p":0,"cluster_ids":["0","1_2","2_34"],"attributes":null,"url":null},{"arg_id":"Acsv-1_7","argument":"加佐地区の魅力化づくりを進めるべき","x":6.683257,"y":6.294748,"p":0,"cluster_ids":["0","1_8","2_56"],"attributes":null,"url":null},{"arg_id":"Acsv-1_8","argument":"西舞鶴駅と東舞鶴駅の再開発を行うべき","x":7.55378,"y":5.373621,"p":0,"cluster_ids":["0","1_8","2_48"],"attributes":null,"url":null},{"arg_id":"Acsv-1_9","argument":"地元の子が地元の高校に進学できるようにするべき","x":4.332562,"y":9.12385,"p":0,"cluster_ids":["0","1_3","2_39"],"attributes":null,"url":null},{"arg_id":"Acsv-2_0","argument":"舞鶴の人口を増やすべきである。","x":7.7531996,"y":5.620516,"p":0,"cluster_ids":["0","1_8","2_6"],"attributes":null,"url":null},{"arg_id":"Acsv-2_1","argument":"大学をつくるべきである。","x":3.988717,"y":9.317023,"p":0,"cluster_ids":["0","1_3","2_39"],"attributes":null,"url":null},{"arg_id":"Acsv-3_0","argument":"舞鶴に青少年団体や学校、こども園、幼稚園、保育園が繋がれる枠組みを作るべき","x":7.542868,"y":6.018813,"p":0,"cluster_ids":["0","1_8","2_6"],"attributes":null,"url":null},{"arg_id":"Acsv-3_1","argument":"指導者の育成や子ども達の繋がりを促進し、選択肢を増やすべき","x":3.2068245,"y":8.6910305,"p":0,"cluster_ids":["0","1_1","2_41"],"attributes":null,"url":null},{"arg_id":"Acsv-3_2","argument":"社会で子供を育てることができる街にするべき","x":2.7992299,"y":8.19573,"p":0,"cluster_ids":["0","1_2","2_30"],"attributes":null,"url":null},{"arg_id":"Acsv-4_0","argument":"学校給食はオーガニック化すべきである。","x":2.4088364,"y":9.37461,"p":0,"cluster_ids":["0","1_1","2_55"],"attributes":null,"url":null},{"arg_id":"Acsv-4_1","argument":"地産地消を推進するべきである。","x":6.4286833,"y":6.7181606,"p":0,"cluster_ids":["0","1_8","2_14"],"attributes":null,"url":null},{"arg_id":"Acsv-5_0","argument":"東西のシャッター街を復興するために、子どもが自由に立ち寄って遊べる場所を作るべきである。","x":5.5422626,"y":6.5207906,"p":0,"cluster_ids":["0","1_5","2_44"],"attributes":null,"url":null},{"arg_id":"Acsv-5_1","argument":"店舗が復活しない理由を聞き取り、支援できるなら支援するべきである。","x":5.8204684,"y":7.6523614,"p":0,"cluster_ids":["0","1_7","2_53"],"attributes":null,"url":null},{"arg_id":"Acsv-5_2","argument":"芸術活動の場を作り、活動を誘致することが重要である。","x":5.0376606,"y":7.2347875,"p":0,"cluster_ids":["0","1_3","2_0"],"attributes":null,"url":null},{"arg_id":"Acsv-5_3","argument":"親子をひき寄せ、最終的に商業的に成り立つよう誘導する必要がある。","x":6.265498,"y":8.205763,"p":0,"cluster_ids":["0","1_7","2_12"],"attributes":null,"url":null},{"arg_id":"Acsv-6_0","argument":"新しい図書館を活用して教育環境を充実させたい","x":3.4432194,"y":9.122803,"p":0,"cluster_ids":["0","1_1","2_8"],"attributes":null,"url":null},{"arg_id":"Acsv-6_1","argument":"全世代が参加できる生涯学習の仕組みを作りたい","x":3.6539452,"y":8.741489,"p":0,"cluster_ids":["0","1_1","2_8"],"attributes":null,"url":null},{"arg_id":"Acsv-6_2","argument":"誰でも意見を言いやすい仕組みを作りたい","x":3.7116418,"y":8.144441,"p":0,"cluster_ids":["0","1_3","2_28"],"attributes":null,"url":null},{"arg_id":"Acsv-7_0","argument":"この病院で完結する、一つの大きな病院を作るべきである。","x":3.2190518,"y":6.66955,"p":0,"cluster_ids":["0","1_2","2_34"],"attributes":null,"url":null},{"arg_id":"Acsv-7_1","argument":"その病院にはドクターヘリを完備すべきである。","x":3.2310803,"y":6.676343,"p":0,"cluster_ids":["0","1_2","2_34"],"attributes":null,"url":null},{"arg_id":"Acsv-7_2","argument":"高潮対策を進めるべきである。","x":5.7197757,"y":4.787918,"p":0,"cluster_ids":["0","1_6","2_50"],"attributes":null,"url":null},{"arg_id":"Acsv-8_0","argument":"働く場所の確保が重要である","x":4.157531,"y":6.7439833,"p":0,"cluster_ids":["0","1_5","2_13"],"attributes":null,"url":null},{"arg_id":"Acsv-8_1","argument":"企業の誘致を進めるために税制優遇を提供すべき","x":5.789034,"y":8.141384,"p":0,"cluster_ids":["0","1_7","2_20"],"attributes":null,"url":null},{"arg_id":"Acsv-8_2","argument":"舞鶴に通勤してくる人を増やすべき","x":7.7481914,"y":5.707996,"p":0,"cluster_ids":["0","1_8","2_6"],"attributes":null,"url":null},{"arg_id":"Acsv-8_3","argument":"人、物、金が集まることで地域が発展する","x":4.5940576,"y":7.568963,"p":0,"cluster_ids":["0","1_3","2_40"],"attributes":null,"url":null},{"arg_id":"Acsv-8_4","argument":"現代の楽市楽座のような環境を作るべき","x":6.213149,"y":6.316064,"p":0,"cluster_ids":["0","1_8","2_14"],"attributes":null,"url":null},{"arg_id":"Acsv-9_0","argument":"大型ショッピングモールの誘致が必要である。","x":6.4808407,"y":7.3467264,"p":0,"cluster_ids":["0","1_7","2_33"],"attributes":null,"url":null},{"arg_id":"Acsv-9_1","argument":"誘致場所は東インター近くが適している。","x":6.6738358,"y":7.3534236,"p":0,"cluster_ids":["0","1_7","2_57"],"attributes":null,"url":null},{"arg_id":"Acsv-10_0","argument":"研究開発に励む企業を支援することで、市内企業の技術力を向上させるべきである。","x":5.748391,"y":8.273476,"p":0,"cluster_ids":["0","1_7","2_20"],"attributes":null,"url":null},{"arg_id":"Acsv-10_1","argument":"補助金などを上手く活用できる仕組みを作る必要がある。","x":3.1273708,"y":7.424842,"p":0,"cluster_ids":["0","1_2","2_62"],"attributes":null,"url":null},{"arg_id":"Acsv-10_2","argument":"知財関連にも既存の補助金を使えるように制度を変え、周知するべきである。","x":2.9008555,"y":7.439902,"p":0,"cluster_ids":["0","1_2","2_62"],"attributes":null,"url":null},{"arg_id":"Acsv-10_3","argument":"市内企業の技術力が上がることで、理系学生のUターン先として選ばれる企業が増えることを目指すべきである。","x":5.6475163,"y":8.322246,"p":0,"cluster_ids":["0","1_7","2_20"],"attributes":null,"url":null},{"arg_id":"Acsv-10_4","argument":"雇用・人口減問題の解決手段の一つとして機能させる必要がある。","x":1.8667321,"y":5.982923,"p":0,"cluster_ids":["0","1_4","2_16"],"attributes":null,"url":null},{"arg_id":"Acsv-11_0","argument":"今ある場所や施設を生かして観光に繋げるべきである。","x":6.0892696,"y":5.702911,"p":0,"cluster_ids":["0","1_8","2_29"],"attributes":null,"url":null},{"arg_id":"Acsv-11_1","argument":"高齢者や子供が雲海や雪景色を見られるように、通行止めになっているケーブルを改善する必要がある。","x":5.6190906,"y":4.9689827,"p":0,"cluster_ids":["0","1_6","2_50"],"attributes":null,"url":null},{"arg_id":"Acsv-11_2","argument":"雲海や雪景色を見に行ける観光客を増やすための施策が必要である。","x":6.081887,"y":5.338766,"p":0,"cluster_ids":["0","1_8","2_1"],"attributes":null,"url":null},{"arg_id":"Acsv-12_0","argument":"子育て支援を充実させるべきである。","x":2.8154995,"y":7.8404055,"p":0,"cluster_ids":["0","1_2","2_42"],"attributes":null,"url":null},{"arg_id":"Acsv-12_1","argument":"舞鶴は転勤族が多いが、子育て支援を充実させることで「ずっと住みたい！」と思ってもらえるようにするべきである。","x":7.760151,"y":5.87024,"p":0,"cluster_ids":["0","1_8","2_6"],"attributes":null,"url":null},{"arg_id":"Acsv-13_0","argument":"電車やバスの本数を増やし、タクシーの代金を安くするなど交通の便を良くすべき","x":6.150379,"y":3.5971377,"p":0,"cluster_ids":["0","1_6","2_23"],"attributes":null,"url":null},{"arg_id":"Acsv-13_1","argument":"子供に対するお金をもっとかけて少子高齢化の対策を進めるべき","x":2.2593977,"y":7.011787,"p":0,"cluster_ids":["0","1_4","2_45"],"attributes":null,"url":null},{"arg_id":"Acsv-13_2","argument":"学校などでインターネットを使った教育を見直すべき","x":3.5535648,"y":9.561787,"p":0,"cluster_ids":["0","1_1","2_52"],"attributes":null,"url":null},{"arg_id":"Acsv-13_3","argument":"子育てしたいと思える施設を充実させるべき","x":3.4807143,"y":7.2491317,"p":0,"cluster_ids":["0","1_2","2_38"],"attributes":null,"url":null},{"arg_id":"Acsv-14_0","argument":"地域の活動において、自主的に会を運営する場を作るべきである。","x":4.793457,"y":7.477884,"p":0,"cluster_ids":["0","1_3","2_40"],"attributes":null,"url":null},{"arg_id":"Acsv-14_1","argument":"互いに応援したくなるような場づくりが重要である。","x":3.2119598,"y":7.662576,"p":0,"cluster_ids":["0","1_2","2_62"],"attributes":null,"url":null},{"arg_id":"Acsv-15_0","argument":"病児保育などの子育て支援が必要である","x":2.8038995,"y":7.6970997,"p":0,"cluster_ids":["0","1_2","2_42"],"attributes":null,"url":null},{"arg_id":"Acsv-15_1","argument":"資格を持っている人が生かしきれない状況を改善すべき","x":3.6405234,"y":7.9316316,"p":0,"cluster_ids":["0","1_3","2_28"],"attributes":null,"url":null},{"arg_id":"Acsv-15_2","argument":"60代以上の方でも働ける環境を整えるべき","x":4.139852,"y":6.9214973,"p":0,"cluster_ids":["0","1_5","2_13"],"attributes":null,"url":null},{"arg_id":"Acsv-15_3","argument":"年代を越えた繋がりを生む環境や働ける場所を作るべき","x":4.225745,"y":7.2336273,"p":0,"cluster_ids":["0","1_5","2_13"],"attributes":null,"url":null},{"arg_id":"Acsv-16_0","argument":"近郊都市部への通勤経路（直通バス）の充実が必要である","x":6.4333773,"y":3.8208954,"p":0,"cluster_ids":["0","1_6","2_27"],"attributes":null,"url":null},{"arg_id":"Acsv-16_1","argument":"リモートワークに使える施設の充実が必要である","x":4.6933465,"y":6.06018,"p":0,"cluster_ids":["0","1_5","2_63"],"attributes":null,"url":null},{"arg_id":"Acsv-16_2","argument":"空き家マッチングを進めるべきである","x":4.225845,"y":5.299953,"p":0,"cluster_ids":["0","1_5","2_18"],"attributes":null,"url":null},{"arg_id":"Acsv-16_3","argument":"高速バスでの通勤が便利であり、時間が合えば移住者が増えると思う","x":6.464805,"y":3.6101532,"p":0,"cluster_ids":["0","1_6","2_27"],"attributes":null,"url":null},{"arg_id":"Acsv-17_0","argument":"鉄道の駅を増やすべきである","x":6.030023,"y":3.9974473,"p":0,"cluster_ids":["0","1_6","2_10"],"attributes":null,"url":null},{"arg_id":"Acsv-17_1","argument":"学校や大きな施設近くに駅ができると便利である","x":6.397404,"y":3.8614643,"p":0,"cluster_ids":["0","1_6","2_27"],"attributes":null,"url":null},{"arg_id":"Acsv-18_0","argument":"市民が無料で使える休憩スペースを作るべき","x":5.071424,"y":6.101221,"p":0,"cluster_ids":["0","1_5","2_11"],"attributes":null,"url":null},{"arg_id":"Acsv-18_1","argument":"市民が無料で使えるコワーキングスペースを作るべき","x":5.2459865,"y":6.2586455,"p":0,"cluster_ids":["0","1_5","2_11"],"attributes":null,"url":null},{"arg_id":"Acsv-19_0","argument":"想像できない","x":3.6962032,"y":7.352449,"p":0,"cluster_ids":["0","1_2","2_38"],"attributes":null,"url":null},{"arg_id":"Acsv-20_0","argument":"教育を重視すべき","x":3.1878114,"y":9.408434,"p":0,"cluster_ids":["0","1_1","2_2"],"attributes":null,"url":null},{"arg_id":"Acsv-20_1","argument":"観光業を発展させるべき","x":6.405535,"y":6.4387665,"p":0,"cluster_ids":["0","1_8","2_14"],"attributes":null,"url":null},{"arg_id":"Acsv-23_0","argument":"結婚支援金を提供すべき","x":2.5877917,"y":7.59271,"p":0,"cluster_ids":["0","1_2","2_17"],"attributes":null,"url":null},{"arg_id":"Acsv-23_1","argument":"子育て支援金を提供すべき","x":2.5020916,"y":7.7630143,"p":0,"cluster_ids":["0","1_2","2_17"],"attributes":null,"url":null},{"arg_id":"Acsv-23_2","argument":"学校教育を充実させるべき","x":3.5641427,"y":9.34117,"p":0,"cluster_ids":["0","1_1","2_52"],"attributes":null,"url":null},{"arg_id":"Acsv-24_0","argument":"女性が生き生き暮らすためには、それぞれの年齢においてしたいことが変わってくるべきである。","x":3.9726248,"y":6.2884016,"p":0,"cluster_ids":["0","1_5","2_54"],"attributes":null,"url":null},{"arg_id":"Acsv-24_1","argument":"舞鶴市には、自分の未来を描ける環境が整っている。","x":7.805892,"y":5.6608214,"p":0,"cluster_ids":["0","1_8","2_6"],"attributes":null,"url":null},{"arg_id":"Acsv-25_0","argument":"教育に関わる人達の質を高めるべき","x":3.2121363,"y":8.871369,"p":0,"cluster_ids":["0","1_1","2_41"],"attributes":null,"url":null},{"arg_id":"Acsv-25_1","argument":"教育に関わる人達は道徳心を持ち、子供達の見本となるべき","x":3.0816307,"y":8.9418125,"p":0,"cluster_ids":["0","1_1","2_41"],"attributes":null,"url":null},{"arg_id":"Acsv-26_0","argument":"交通の便を良くするために再開発を行うべき","x":5.700039,"y":3.8126175,"p":0,"cluster_ids":["0","1_6","2_10"],"attributes":null,"url":null},{"arg_id":"Acsv-26_1","argument":"臨海部の開発を進めるべき","x":5.853921,"y":4.4910016,"p":0,"cluster_ids":["0","1_6","2_4"],"attributes":null,"url":null},{"arg_id":"Acsv-27_0","argument":"ジャンカラを誘致すべき","x":6.656712,"y":6.9456377,"p":0,"cluster_ids":["0","1_7","2_57"],"attributes":null,"url":null},{"arg_id":"Acsv-28_0","argument":"教育環境を充実させるべきである。","x":3.1818237,"y":9.339884,"p":0,"cluster_ids":["0","1_1","2_2"],"attributes":null,"url":null},{"arg_id":"Acsv-29_0","argument":"バスの両替機をリニューアルすべきである。","x":6.074711,"y":3.482999,"p":0,"cluster_ids":["0","1_6","2_23"],"attributes":null,"url":null},{"arg_id":"Acsv-30_0","argument":"公共交通を充実させるべきである。","x":5.588585,"y":3.7798057,"p":0,"cluster_ids":["0","1_6","2_10"],"attributes":null,"url":null},{"arg_id":"Acsv-31_0","argument":"バスと電車の本数を増やし、どこでも行きやすいようにするべきである。","x":6.252872,"y":3.5541008,"p":0,"cluster_ids":["0","1_6","2_27"],"attributes":null,"url":null},{"arg_id":"Acsv-31_1","argument":"文化や芸術を身近に感じられる大規模イベントを増やすべきである。","x":4.9192243,"y":7.0071216,"p":0,"cluster_ids":["0","1_3","2_0"],"attributes":null,"url":null},{"arg_id":"Acsv-31_2","argument":"プレイバックフェスを継続させるべきである。","x":5.0060935,"y":5.0068145,"p":0,"cluster_ids":["0","1_5","2_47"],"attributes":null,"url":null},{"arg_id":"Acsv-32_0","argument":"公共交通を充実させるべき","x":5.7186956,"y":3.648905,"p":0,"cluster_ids":["0","1_6","2_10"],"attributes":null,"url":null},{"arg_id":"Acsv-32_1","argument":"公園や広場の整備を行うべき","x":5.346671,"y":5.5671897,"p":0,"cluster_ids":["0","1_5","2_36"],"attributes":null,"url":null},{"arg_id":"Acsv-33_0","argument":"人口減少が進むため、より広域な公共団体が必要である。","x":1.567623,"y":5.780636,"p":0,"cluster_ids":["0","1_4","2_16"],"attributes":null,"url":null},{"arg_id":"Acsv-33_1","argument":"様々な能力・知識・性格を持つ人々が自分の力を発揮できる社会をつくるべきである。","x":3.8514688,"y":8.021969,"p":0,"cluster_ids":["0","1_3","2_28"],"attributes":null,"url":null},{"arg_id":"Acsv-33_2","argument":"休暇や休息を適度に取れる社会を実現すべきである。","x":4.6090317,"y":6.43646,"p":0,"cluster_ids":["0","1_5","2_58"],"attributes":null,"url":null},{"arg_id":"Acsv-34_0","argument":"娯楽や飲食店等のバリエーション及び店舗数を拡大すべき","x":6.1187644,"y":7.55904,"p":0,"cluster_ids":["0","1_7","2_5"],"attributes":null,"url":null},{"arg_id":"Acsv-37_0","argument":"西舞鶴駅の東口を通る路線バスの導入が必要である","x":7.550378,"y":5.151132,"p":0,"cluster_ids":["0","1_8","2_48"],"attributes":null,"url":null},{"arg_id":"Acsv-38_0","argument":"医療介護に力を入れるべきである","x":3.103654,"y":6.88047,"p":0,"cluster_ids":["0","1_2","2_34"],"attributes":null,"url":null},{"arg_id":"Acsv-40_0","argument":"通学路の安全確保のために歩道の整備が必要である","x":5.0277143,"y":4.281239,"p":0,"cluster_ids":["0","1_6","2_21"],"attributes":null,"url":null},{"arg_id":"Acsv-40_1","argument":"小児医療の充実が求められる","x":2.9339445,"y":7.146532,"p":0,"cluster_ids":["0","1_2","2_7"],"attributes":null,"url":null},{"arg_id":"Acsv-41_0","argument":"大学を誘致すべき","x":4.294654,"y":9.2985735,"p":0,"cluster_ids":["0","1_3","2_39"],"attributes":null,"url":null},{"arg_id":"Acsv-41_1","argument":"大型商業施設を誘致すべき","x":6.578589,"y":7.397068,"p":0,"cluster_ids":["0","1_7","2_57"],"attributes":null,"url":null},{"arg_id":"Acsv-41_2","argument":"青少年団体や指導者が共に学び、情報交換できる団体を創設すべき","x":3.8898487,"y":8.496668,"p":0,"cluster_ids":["0","1_3","2_46"],"attributes":null,"url":null},{"arg_id":"Acsv-41_3","argument":"地域全体で青少年の健全な育成を行うために研修や合同合宿を実施すべき","x":4.0590863,"y":8.572935,"p":0,"cluster_ids":["0","1_3","2_46"],"attributes":null,"url":null},{"arg_id":"Acsv-43_0","argument":"ポイ捨てを減らすべきである。","x":2.298083,"y":5.487206,"p":0,"cluster_ids":["0","1_4","2_31"],"attributes":null,"url":null},{"arg_id":"Acsv-44_0","argument":"商店街に店を作るべきである。","x":6.114998,"y":7.4175444,"p":0,"cluster_ids":["0","1_7","2_5"],"attributes":null,"url":null},{"arg_id":"Acsv-45_0","argument":"歴史的建造物のアピールを増やすべきである。","x":4.8593435,"y":5.4654994,"p":0,"cluster_ids":["0","1_5","2_24"],"attributes":null,"url":null},{"arg_id":"Acsv-46_0","argument":"仕事を充実させるべきである。","x":4.0831313,"y":6.778752,"p":0,"cluster_ids":["0","1_5","2_13"],"attributes":null,"url":null},{"arg_id":"Acsv-47_0","argument":"中学生(子供)の遊べる施設を増やすべき","x":4.3532696,"y":8.8505945,"p":0,"cluster_ids":["0","1_3","2_22"],"attributes":null,"url":null},{"arg_id":"Acsv-48_0","argument":"舞鶴の良さを知ってもらうべきである","x":7.9027457,"y":5.818958,"p":0,"cluster_ids":["0","1_8","2_6"],"attributes":null,"url":null},{"arg_id":"Acsv-49_0","argument":"人口減少は社会にさまざまな影響を及ぼす問題である。","x":1.6610192,"y":5.9644537,"p":0,"cluster_ids":["0","1_4","2_16"],"attributes":null,"url":null},{"arg_id":"Acsv-50_0","argument":"少子高齢化は社会に多くの影響を与える重要な問題である。","x":1.9423511,"y":6.4364753,"p":0,"cluster_ids":["0","1_4","2_3"],"attributes":null,"url":null},{"arg_id":"Acsv-51_0","argument":"海の周りを綺麗にするべきである。","x":6.0675745,"y":4.8880396,"p":0,"cluster_ids":["0","1_6","2_59"],"attributes":null,"url":null},{"arg_id":"Acsv-53_0","argument":"人口減少の課題に取り組むべきである。","x":1.7717618,"y":5.782708,"p":0,"cluster_ids":["0","1_4","2_16"],"attributes":null,"url":null},{"arg_id":"Acsv-55_0","argument":"人口減少を解決するために人を集めるべきである。","x":1.5948005,"y":5.709495,"p":0,"cluster_ids":["0","1_4","2_16"],"attributes":null,"url":null},{"arg_id":"Acsv-56_0","argument":"家を増やすべきである。","x":4.4663186,"y":5.4392023,"p":0,"cluster_ids":["0","1_5","2_18"],"attributes":null,"url":null},{"arg_id":"Acsv-60_0","argument":"網を海と川の境目に張るべきである。","x":5.8953,"y":4.605915,"p":0,"cluster_ids":["0","1_6","2_4"],"attributes":null,"url":null},{"arg_id":"Acsv-61_0","argument":"人口減少は社会や経済にさまざまな影響を及ぼす問題である。","x":1.7356107,"y":6.0050035,"p":0,"cluster_ids":["0","1_4","2_16"],"attributes":null,"url":null},{"arg_id":"Acsv-62_0","argument":"就職先の衰退が問題である。","x":1.9951178,"y":6.195052,"p":0,"cluster_ids":["0","1_4","2_3"],"attributes":null,"url":null},{"arg_id":"Acsv-63_0","argument":"人口減少は重要な社会問題である。","x":1.7391462,"y":5.8738065,"p":0,"cluster_ids":["0","1_4","2_16"],"attributes":null,"url":null},{"arg_id":"Acsv-64_0","argument":"人口を増加させるべきである","x":1.5283165,"y":5.6332355,"p":0,"cluster_ids":["0","1_4","2_16"],"attributes":null,"url":null},{"arg_id":"Acsv-66_0","argument":"生徒にとって充実した教育環境が必要である。","x":3.3358536,"y":9.46017,"p":0,"cluster_ids":["0","1_1","2_52"],"attributes":null,"url":null},{"arg_id":"Acsv-68_0","argument":"人数の少ない学校を統合して教育環境を充実させるべき","x":3.6218712,"y":9.198572,"p":0,"cluster_ids":["0","1_1","2_8"],"attributes":null,"url":null},{"arg_id":"Acsv-68_1","argument":"スポーツなど子どもの習い事を支援すべき","x":2.8508136,"y":7.806567,"p":0,"cluster_ids":["0","1_2","2_42"],"attributes":null,"url":null},{"arg_id":"Acsv-69_0","argument":"子育て世代を支えるべきである。","x":2.6026049,"y":7.5709515,"p":0,"cluster_ids":["0","1_2","2_17"],"attributes":null,"url":null},{"arg_id":"Acsv-69_1","argument":"若い人が仕事をしたいと思う仕事先を誘致する必要がある。","x":5.025904,"y":7.9261055,"p":0,"cluster_ids":["0","1_3","2_60"],"attributes":null,"url":null},{"arg_id":"Acsv-432_0","argument":"道路を改良すべきである。","x":5.521565,"y":4.170108,"p":0,"cluster_ids":["0","1_6","2_43"],"attributes":null,"url":null},{"arg_id":"Acsv-434_0","argument":"学校の給食で、食べられるものを増やしてほしい。","x":2.3564756,"y":9.33593,"p":0,"cluster_ids":["0","1_1","2_55"],"attributes":null,"url":null},{"arg_id":"Acsv-434_1","argument":"みんなが楽しく給食を食べられるようにしたい。","x":2.2259612,"y":9.210311,"p":0,"cluster_ids":["0","1_1","2_19"],"attributes":null,"url":null},{"arg_id":"Acsv-434_2","argument":"食品アレルギーや感覚過敏など、多様な特性や好みを尊重する学校にしていくべき。","x":2.4049716,"y":9.435407,"p":0,"cluster_ids":["0","1_1","2_55"],"attributes":null,"url":null},{"arg_id":"Acsv-434_3","argument":"好き嫌いせず食べることを重視する古い価値観をアップデートする必要がある。","x":2.1479115,"y":9.257779,"p":0,"cluster_ids":["0","1_1","2_19"],"attributes":null,"url":null},{"arg_id":"Acsv-434_4","argument":"人間理解を深め、人権が尊重される社会を目指すべき。","x":4.0230737,"y":7.891977,"p":0,"cluster_ids":["0","1_3","2_15"],"attributes":null,"url":null},{"arg_id":"Acsv-434_5","argument":"教職員が自閉スペクトラム症などに対する理解を深める機会を作ることが大切。","x":3.2178855,"y":8.820695,"p":0,"cluster_ids":["0","1_1","2_41"],"attributes":null,"url":null},{"arg_id":"Acsv-435_0","argument":"学校生活を大人による指示・命令主体から、子どもとの相談・提案をベースとしたコミュニケーションへ転換すべき","x":3.6565871,"y":8.997645,"p":0,"cluster_ids":["0","1_1","2_8"],"attributes":null,"url":null},{"arg_id":"Acsv-435_1","argument":"失敗は価値あるデータというカルチャーを醸成し、挑戦を称える教育環境を整えるべき","x":3.261701,"y":9.389851,"p":0,"cluster_ids":["0","1_1","2_2"],"attributes":null,"url":null},{"arg_id":"Acsv-435_2","argument":"異文化、異世代、異生物に対して心を開き、多面的な交流を通じて多様な価値観を尊重できる街の土壌を作るべき","x":4.162539,"y":7.845648,"p":0,"cluster_ids":["0","1_3","2_15"],"attributes":null,"url":null},{"arg_id":"Acsv-435_3","argument":"市民一人ひとりが自走して助け合える備えを強化すべき","x":4.8861537,"y":6.4211707,"p":0,"cluster_ids":["0","1_5","2_58"],"attributes":null,"url":null},{"arg_id":"Acsv-436_0","argument":"赤レンガパークの観光施設を充実させるために、宿泊施設や飲食店を整備し、遊べる場所を増やすべきである。","x":6.072101,"y":5.8187804,"p":0,"cluster_ids":["0","1_8","2_29"],"attributes":null,"url":null},{"arg_id":"Acsv-436_1","argument":"市役所を改造してホテルにし、旧スキー場を整備してショッピングモールを新設することが解決策として提案されている。","x":5.9750667,"y":6.6750927,"p":0,"cluster_ids":["0","1_8","2_35"],"attributes":null,"url":null},{"arg_id":"Acsv-436_2","argument":"夕潮台公園を改造し、グランピング・キャンピング施設や小さな遊園地を新設することで、市民と観光客が楽しめる場所を作るべきである。","x":5.9057856,"y":5.6946983,"p":0,"cluster_ids":["0","1_8","2_29"],"attributes":null,"url":null},{"arg_id":"Acsv-436_3","argument":"赤レンガパーク周辺をロープウェイで結び、舞鶴湾を一望できる移動手段を提供することが重要である。","x":6.518024,"y":5.5171137,"p":0,"cluster_ids":["0","1_8","2_51"],"attributes":null,"url":null},{"arg_id":"Acsv-436_4","argument":"自転車道路や北吸トンネルの整備を行い、清掃活動を定期的に実施することで、観光名所としての魅力を高めるべきである。","x":6.1751814,"y":5.303417,"p":0,"cluster_ids":["0","1_8","2_1"],"attributes":null,"url":null},{"arg_id":"Acsv-436_5","argument":"主要商店街の整備・改修を行い、企業誘致を進めることで、活気のある商店街を作る必要がある。","x":6.072032,"y":7.3756247,"p":0,"cluster_ids":["0","1_7","2_5"],"attributes":null,"url":null},{"arg_id":"Acsv-437_0","argument":"赤レンガパークの観光施設を充実させるために、宿泊施設や飲食店を整備し、滞在できる環境を整えるべきである。","x":5.9931006,"y":5.783935,"p":0,"cluster_ids":["0","1_8","2_29"],"attributes":null,"url":null},{"arg_id":"Acsv-437_1","argument":"市役所を改造してホテルにし、旧スキー場を整備してショッピングモールを新設することが必要である。","x":5.984286,"y":6.6184125,"p":0,"cluster_ids":["0","1_8","2_35"],"attributes":null,"url":null},{"arg_id":"Acsv-437_2","argument":"夕潮台公園を改造し、グランピング・キャンピング施設や小さな遊園地を新設することで、遊びの場を提供すべきである。","x":5.8797865,"y":5.8341727,"p":0,"cluster_ids":["0","1_8","2_29"],"attributes":null,"url":null},{"arg_id":"Acsv-437_3","argument":"旧スキー場、atick、夕潮台公園をロープウェイで結び、観光名所としての魅力を高めるべきである。","x":6.290309,"y":5.6067834,"p":0,"cluster_ids":["0","1_8","2_51"],"attributes":null,"url":null},{"arg_id":"Acsv-437_4","argument":"自転車道路や北吸トンネルの整備を行い、清掃活動を定期的に実施することで、観光名所の清潔感を保つべきである。","x":6.033812,"y":5.21678,"p":0,"cluster_ids":["0","1_8","2_1"],"attributes":null,"url":null},{"arg_id":"Acsv-437_5","argument":"主要商店街の整備・改修を行い、企業誘致を進めて活気のある商店街を作るべきである。","x":6.003081,"y":7.35696,"p":0,"cluster_ids":["0","1_7","2_5"],"attributes":null,"url":null},{"arg_id":"Acsv-441_0","argument":"教育環境を充実させるべきである","x":3.2056224,"y":9.14379,"p":0,"cluster_ids":["0","1_1","2_26"],"attributes":null,"url":null},{"arg_id":"Acsv-442_0","argument":"ポイ捨てなどを罰金にするべきである。","x":2.3999958,"y":5.661999,"p":0,"cluster_ids":["0","1_4","2_31"],"attributes":null,"url":null},{"arg_id":"Acsv-444_0","argument":"学校を増やすべきである","x":4.0791845,"y":9.162351,"p":0,"cluster_ids":["0","1_3","2_39"],"attributes":null,"url":null},{"arg_id":"Acsv-446_0","argument":"産業は経済の基盤であり、持続可能な成長を促進するために革新が必要である。","x":6.260408,"y":8.48716,"p":0,"cluster_ids":["0","1_7","2_12"],"attributes":null,"url":null},{"arg_id":"Acsv-447_0","argument":"施設を増やすべきである。","x":5.103379,"y":5.5872965,"p":0,"cluster_ids":["0","1_5","2_36"],"attributes":null,"url":null},{"arg_id":"Acsv-449_0","argument":"都市に協力する必要がある","x":5.135592,"y":6.61828,"p":0,"cluster_ids":["0","1_5","2_58"],"attributes":null,"url":null},{"arg_id":"Acsv-450_0","argument":"環境問題は重要な課題であり、解決に向けた取り組みが必要である。","x":2.5991042,"y":5.145911,"p":0,"cluster_ids":["0","1_4","2_9"],"attributes":null,"url":null},{"arg_id":"Acsv-451_0","argument":"教育環境をよくするべきである","x":2.9463644,"y":9.238469,"p":0,"cluster_ids":["0","1_1","2_26"],"attributes":null,"url":null},{"arg_id":"Acsv-453_0","argument":"労働者不足を改善したい","x":3.9592423,"y":6.9573903,"p":0,"cluster_ids":["0","1_5","2_13"],"attributes":null,"url":null},{"arg_id":"Acsv-454_0","argument":"交通整備をするべきである。","x":5.314456,"y":3.9499457,"p":0,"cluster_ids":["0","1_6","2_43"],"attributes":null,"url":null},{"arg_id":"Acsv-455_0","argument":"交通を便利にするべきである","x":5.6591377,"y":3.6100562,"p":0,"cluster_ids":["0","1_6","2_10"],"attributes":null,"url":null},{"arg_id":"Acsv-455_1","argument":"建物を増やすべきである","x":4.6825776,"y":5.472997,"p":0,"cluster_ids":["0","1_5","2_24"],"attributes":null,"url":null},{"arg_id":"Acsv-457_0","argument":"住宅や公共施設やスポーツ施設の安全を快適化すべき","x":5.1196556,"y":5.647557,"p":0,"cluster_ids":["0","1_5","2_36"],"attributes":null,"url":null},{"arg_id":"Acsv-459_0","argument":"進路先を増やすために教育環境を整えるべきである。","x":3.0633237,"y":9.523764,"p":0,"cluster_ids":["0","1_1","2_2"],"attributes":null,"url":null},{"arg_id":"Acsv-461_0","argument":"施設を整備する必要がある","x":4.913725,"y":5.8036184,"p":0,"cluster_ids":["0","1_5","2_36"],"attributes":null,"url":null},{"arg_id":"Acsv-463_0","argument":"店を発展させるべきである","x":6.1998262,"y":7.78615,"p":0,"cluster_ids":["0","1_7","2_5"],"attributes":null,"url":null},{"arg_id":"Acsv-464_0","argument":"人口を増やして、お店を増やすべきである。","x":6.1839414,"y":7.360443,"p":0,"cluster_ids":["0","1_7","2_5"],"attributes":null,"url":null},{"arg_id":"Acsv-465_0","argument":"産業の発展は経済成長に寄与する重要な要素である。","x":6.2721972,"y":8.543052,"p":0,"cluster_ids":["0","1_7","2_12"],"attributes":null,"url":null},{"arg_id":"Acsv-467_0","argument":"教育しやすい環境をつくるべきである","x":2.891693,"y":9.173804,"p":0,"cluster_ids":["0","1_1","2_26"],"attributes":null,"url":null},{"arg_id":"Acsv-468_0","argument":"交通機関を増やすべきである。","x":5.881353,"y":3.4447672,"p":0,"cluster_ids":["0","1_6","2_23"],"attributes":null,"url":null},{"arg_id":"Acsv-470_0","argument":"公共施設を充実させるべきである。","x":5.2167797,"y":5.4920692,"p":0,"cluster_ids":["0","1_5","2_36"],"attributes":null,"url":null},{"arg_id":"Acsv-471_0","argument":"町の活気を取り戻すべきである。","x":6.0178437,"y":7.1946473,"p":0,"cluster_ids":["0","1_7","2_5"],"attributes":null,"url":null},{"arg_id":"Acsv-472_0","argument":"交通機関を増発すべきであり、一時間に一本程度から一時間に四本にするべきである。","x":6.1039686,"y":3.5005329,"p":0,"cluster_ids":["0","1_6","2_23"],"attributes":null,"url":null},{"arg_id":"Acsv-473_0","argument":"商業施設を増やして、若い人たちが大人になっても舞鶴にいたいと思えるような遊び場を増やすべき","x":7.178043,"y":6.082922,"p":0,"cluster_ids":["0","1_8","2_32"],"attributes":null,"url":null},{"arg_id":"Acsv-474_0","argument":"環境問題を減らすべきである。","x":2.5032532,"y":5.153611,"p":0,"cluster_ids":["0","1_4","2_9"],"attributes":null,"url":null},{"arg_id":"Acsv-475_0","argument":"交通手段を増やすべきである","x":5.5757346,"y":3.6985507,"p":0,"cluster_ids":["0","1_6","2_10"],"attributes":null,"url":null},{"arg_id":"Acsv-477_0","argument":"道路の整備を今のうちにするべき","x":5.277686,"y":4.1962204,"p":0,"cluster_ids":["0","1_6","2_43"],"attributes":null,"url":null},{"arg_id":"Acsv-477_1","argument":"水道の配管を点検するべき","x":5.3303943,"y":4.540104,"p":0,"cluster_ids":["0","1_6","2_21"],"attributes":null,"url":null},{"arg_id":"Acsv-478_0","argument":"産業を発展させるべきである。","x":6.151038,"y":8.397965,"p":0,"cluster_ids":["0","1_7","2_12"],"attributes":null,"url":null},{"arg_id":"Acsv-479_0","argument":"ゴミの問題は深刻であり、持続可能な解決策が必要である。","x":2.5250294,"y":5.0832977,"p":0,"cluster_ids":["0","1_4","2_9"],"attributes":null,"url":null},{"arg_id":"Acsv-479_1","argument":"リサイクルや廃棄物削減の取り組みを強化すべきである。","x":2.4040127,"y":5.2151437,"p":0,"cluster_ids":["0","1_4","2_9"],"attributes":null,"url":null},{"arg_id":"Acsv-481_0","argument":"遊ぶ場所を作り、みんなが利用できる公共スペースを設置すべき","x":5.4524302,"y":6.2201986,"p":0,"cluster_ids":["0","1_5","2_44"],"attributes":null,"url":null},{"arg_id":"Acsv-481_1","argument":"高齢者もリラックスできる安心した施設を建設すべき","x":4.5115085,"y":6.010181,"p":0,"cluster_ids":["0","1_5","2_63"],"attributes":null,"url":null},{"arg_id":"Acsv-482_0","argument":"釣り場やグランピングなど、自然を活かしたアウトドアの施設を整備すべき","x":5.697186,"y":5.5320506,"p":0,"cluster_ids":["0","1_8","2_1"],"attributes":null,"url":null},{"arg_id":"Acsv-483_0","argument":"少子高齢化の改善が必要である。","x":2.0974724,"y":6.688907,"p":0,"cluster_ids":["0","1_4","2_45"],"attributes":null,"url":null},{"arg_id":"Acsv-485_0","argument":"公共交通機関を充実させるべきである。","x":5.8735404,"y":3.4363172,"p":0,"cluster_ids":["0","1_6","2_23"],"attributes":null,"url":null},{"arg_id":"Acsv-487_0","argument":"少子高齢化を減らすべきである。","x":2.0727005,"y":6.6048937,"p":0,"cluster_ids":["0","1_4","2_45"],"attributes":null,"url":null},{"arg_id":"Acsv-488_0","argument":"老朽化を少しずつ直していくべきである","x":2.2706685,"y":6.5259986,"p":0,"cluster_ids":["0","1_4","2_45"],"attributes":null,"url":null},{"arg_id":"Acsv-488_1","argument":"環境を大切にすることが重要である","x":2.606833,"y":5.186237,"p":0,"cluster_ids":["0","1_4","2_9"],"attributes":null,"url":null},{"arg_id":"Acsv-489_0","argument":"地球温暖化は深刻な問題であり、対策が必要である。","x":2.5557187,"y":5.075323,"p":0,"cluster_ids":["0","1_4","2_9"],"attributes":null,"url":null},{"arg_id":"Acsv-491_0","argument":"産業の発展は経済の成長に寄与する。","x":6.2941437,"y":8.394845,"p":0,"cluster_ids":["0","1_7","2_12"],"attributes":null,"url":null},{"arg_id":"Acsv-492_0","argument":"舞鶴の自然を活用しながら大型施設を充実させるべきである。","x":7.4750733,"y":5.7508,"p":0,"cluster_ids":["0","1_8","2_6"],"attributes":null,"url":null},{"arg_id":"Acsv-493_0","argument":"雪の問題に取り組む必要がある。","x":3.2523727,"y":4.9355865,"p":0,"cluster_ids":["0","1_4","2_49"],"attributes":null,"url":null},{"arg_id":"Acsv-494_0","argument":"自然を守るべきである。","x":3.6265166,"y":5.9597354,"p":0,"cluster_ids":["0","1_5","2_37"],"attributes":null,"url":null},{"arg_id":"Acsv-495_0","argument":"教育の環境を充実させるべきであり、例えば学校の費用を減らすことが重要である。","x":3.1220577,"y":9.700677,"p":0,"cluster_ids":["0","1_1","2_2"],"attributes":null,"url":null},{"arg_id":"Acsv-495_1","argument":"子育ての支援を充実させるべきである。","x":2.971564,"y":7.755815,"p":0,"cluster_ids":["0","1_2","2_42"],"attributes":null,"url":null},{"arg_id":"Acsv-499_0","argument":"交通機関は、効率的で持続可能な移動手段を提供するべきである。","x":5.8833065,"y":3.330061,"p":0,"cluster_ids":["0","1_6","2_23"],"attributes":null,"url":null},{"arg_id":"Acsv-499_1","argument":"公共交通機関の利用促進が必要である。","x":5.857472,"y":3.333522,"p":0,"cluster_ids":["0","1_6","2_23"],"attributes":null,"url":null},{"arg_id":"Acsv-500_0","argument":"ショッピングモールなどを増やすべきである。","x":6.3359385,"y":7.3505974,"p":0,"cluster_ids":["0","1_7","2_33"],"attributes":null,"url":null},{"arg_id":"Acsv-501_0","argument":"舞鶴の良さを発信するべきである","x":7.9378743,"y":5.8096986,"p":0,"cluster_ids":["0","1_8","2_6"],"attributes":null,"url":null},{"arg_id":"Acsv-501_1","argument":"地域の過疎化を減らすために舞鶴に新しい施設（遊び場など）をつくるべきである","x":7.1627545,"y":5.7499514,"p":0,"cluster_ids":["0","1_8","2_32"],"attributes":null,"url":null},{"arg_id":"Acsv-501_2","argument":"舞鶴の高速道を引き伸ばすべきである","x":7.9131374,"y":5.5475698,"p":0,"cluster_ids":["0","1_8","2_6"],"attributes":null,"url":null},{"arg_id":"Acsv-502_0","argument":"ロードハーディングをするべきである。","x":5.560768,"y":4.1305885,"p":0,"cluster_ids":["0","1_6","2_43"],"attributes":null,"url":null},{"arg_id":"Acsv-503_0","argument":"産業を発展させるべきである","x":6.0539513,"y":8.525434,"p":0,"cluster_ids":["0","1_7","2_12"],"attributes":null,"url":null},{"arg_id":"Acsv-505_0","argument":"インフラを再整備するべきである。","x":4.92514,"y":5.024406,"p":0,"cluster_ids":["0","1_5","2_47"],"attributes":null,"url":null},{"arg_id":"Acsv-506_0","argument":"子供が育てやすい教育環境を充実させるべき","x":2.8777158,"y":8.520857,"p":0,"cluster_ids":["0","1_2","2_30"],"attributes":null,"url":null},{"arg_id":"Acsv-506_1","argument":"高齢者が過ごしやすい環境を整えるための建設を充実させるべき","x":4.2330666,"y":5.973779,"p":0,"cluster_ids":["0","1_5","2_25"],"attributes":null,"url":null},{"arg_id":"Acsv-507_0","argument":"治安の悪い街ではなくていい街を作るために呼びかけるべきである。","x":5.849751,"y":7.0173254,"p":0,"cluster_ids":["0","1_8","2_35"],"attributes":null,"url":null},{"arg_id":"Acsv-508_0","argument":"地域や国の人たちとの“安全”な交流ができる機会を作るべきである。","x":4.558153,"y":7.6525064,"p":0,"cluster_ids":["0","1_3","2_40"],"attributes":null,"url":null},{"arg_id":"Acsv-509_0","argument":"企業誘致や起業家支援を通じて産業の活力を高め、若者の働く場所を増やすべき","x":5.5064616,"y":8.21938,"p":0,"cluster_ids":["0","1_7","2_20"],"attributes":null,"url":null},{"arg_id":"Acsv-509_1","argument":"農漁業の体験を提供し、海・山の魅力を感じてもらうことで移住者の増加を図るべき","x":6.6075573,"y":6.0910263,"p":0,"cluster_ids":["0","1_8","2_56"],"attributes":null,"url":null},{"arg_id":"Acsv-509_2","argument":"子供を産み・育てやすい環境を整えるべき","x":2.7079594,"y":8.231034,"p":0,"cluster_ids":["0","1_2","2_30"],"attributes":null,"url":null},{"arg_id":"Acsv-512_0","argument":"ポイ捨てをしないことが重要である","x":2.4862888,"y":5.598573,"p":0,"cluster_ids":["0","1_4","2_31"],"attributes":null,"url":null},{"arg_id":"Acsv-515_0","argument":"ポイ捨ては環境に悪影響を与える行為である。","x":2.3768504,"y":5.5151367,"p":0,"cluster_ids":["0","1_4","2_31"],"attributes":null,"url":null},{"arg_id":"Acsv-517_0","argument":"給食は無償化だけでなく、おいしいと思えるものにするべき","x":2.1800258,"y":9.153458,"p":0,"cluster_ids":["0","1_1","2_19"],"attributes":null,"url":null},{"arg_id":"Acsv-517_1","argument":"雪が降っても通学路の道が確保されるべき（聾学校の通学路も含む）","x":4.7905207,"y":4.167528,"p":0,"cluster_ids":["0","1_6","2_21"],"attributes":null,"url":null},{"arg_id":"Acsv-517_2","argument":"自然を生かしたアクティビティを充実させるべき","x":3.9731731,"y":6.513604,"p":0,"cluster_ids":["0","1_5","2_54"],"attributes":null,"url":null},{"arg_id":"Acsv-517_3","argument":"自転車用の道路幅を確保し、安全に自転車が乗れる道を整備するべき","x":5.1514673,"y":4.2106147,"p":0,"cluster_ids":["0","1_6","2_21"],"attributes":null,"url":null},{"arg_id":"Acsv-517_4","argument":"新規の出店や地元の小規模店、商店街が活性化する支援を行うべき","x":5.7753067,"y":7.6698413,"p":0,"cluster_ids":["0","1_7","2_53"],"attributes":null,"url":null},{"arg_id":"Acsv-517_5","argument":"少子化の影響はあるが、大学など若者が通う施設を誘致することで、店や下宿先、バイト先も活性化する可能性がある","x":4.6429667,"y":8.499229,"p":0,"cluster_ids":["0","1_3","2_61"],"attributes":null,"url":null},{"arg_id":"Acsv-518_0","argument":"教育環境を充実させるべき","x":3.4469244,"y":9.130759,"p":0,"cluster_ids":["0","1_1","2_8"],"attributes":null,"url":null},{"arg_id":"Acsv-518_1","argument":"地元を好きになるまちを目指すべき","x":6.5517206,"y":6.6790566,"p":0,"cluster_ids":["0","1_8","2_14"],"attributes":null,"url":null}],"clusters":[{"level":0,"id":"0","label":"全体","takeaway":"","value":212,"parent":"","density_rank_percentile":0},{"level":1,"id":"1_8","label":"舞鶴市の観光資源を活用した地域活性化と住みやすい環境の整備","takeaway":"舞鶴市の地域資源を最大限に活用し、観光施設の充実や多様化を図ることで、観光客と市民が共に楽しめる環境を整えることが求められています。具体的には、赤レンガパークや夕潮台公園を中心に宿泊施設や飲食店の整備、自然を活かしたアウトドア施設の整備、交通インフラの改善などが提案されています。また、地域の魅力を高めるための施策として、地産地消の推進や青少年育成の枠組みの構築、移住促進のための農漁業体験の提供などが挙げられ、地域の活性化と住みやすさの向上が目指されています。","value":35,"parent":"0","density_rank_percentile":1},{"level":1,"id":"1_7","label":"地域経済の活性化と持続可能な産業発展の推進","takeaway":"地域の経済を活性化させるためには、大型商業施設やショッピングモールの誘致が不可欠であり、特に東インター近くの立地が適しているとされています。また、地元の小規模店や商店街の支援を通じて新規出店を促進し、地域の魅力を高めることが求められています。さらに、産業の発展を通じて若者の雇用機会を増やし、持続可能な成長を実現するための革新が必要です。企業誘致や起業家支援を行い、地域の技術力向上を図ることで、地域全体の活力を取り戻すことが期待されています。","value":25,"parent":"0","density_rank_percentile":0.375},{"level":1,"id":"1_2","label":"子育て世代と医療介護の充実を目指す地域社会の形成","takeaway":"子育て世代が安心して生活できる環境を整えるため、経済的支援や子育て支援施設の充実が求められています。また、医療介護の統合や専門性の向上を通じて、地域全体で子供を育てるための基盤を強化することが重要です。具体的には、給食や医療の無償化、病児保育の充実、そして小児医療の質とアクセス向上が挙げられます。さらに、知的財産関連の支援体制を整えることで、地域の活性化を図ることも期待されています。","value":22,"parent":"0","density_rank_percentile":0.25},{"level":1,"id":"1_6","label":"地域交通インフラの整備と安全なアクセスの向上","takeaway":"地域の交通インフラを強化し、渋滞を解消するための具体的な施策が求められています。バイパス道路やロードハーディングの整備により、交通の流れを改善し、快適な移動環境を実現することが期待されています。また、高齢者や子供が安全に観光地を訪れるためのアクセス改善や、通学路の安全性向上に向けたインフラ整備も重要視されています。公共交通機関の充実や利用促進を通じて、持続可能な移動手段の確保が求められ、地域経済の活性化にも寄与することが期待されています。","value":31,"parent":"0","density_rank_percentile":0.5},{"level":1,"id":"1_3","label":"地域の人材育成と文化活性化を促進するための包括的な取り組み","takeaway":"地域の教育機関の拡充や進学機会の向上を通じて、地元の子どもたちが教育を受けやすい環境を整えることが求められています。また、文化や芸術の普及を目的とした大規模イベントの推進や、地域の自主的な運営による交流の場の創出が重要です。さらに、若者向けの魅力的な雇用機会の創出や、青少年の健全な育成を目指す研修・交流の促進が地域の活性化に寄与します。多様性を尊重し、誰もが意見を言いやすい社会を築くことで、地域全体の発展が期待されます。","value":19,"parent":"0","density_rank_percentile":0.875},{"level":1,"id":"1_1","label":"教育環境の充実と多様なニーズへの対応","takeaway":"教育者の道徳心や専門性の向上を重視し、子供たちにとっての模範となることが求められています。また、学校給食のオーガニック化や多様性を尊重した食事の提供を通じて、すべての生徒が安心して食べられる環境を整えることが重要です。さらに、教育環境の改善や充実を図るために、少人数の学校の統合や生涯学習の仕組みの構築、インターネットを活用した教育方法の見直しなど、多角的なアプローチが必要とされています。これにより、教育の質を向上させ、進路選択の多様化や子供たちのつながりを促進することが期待されています。","value":26,"parent":"0","density_rank_percentile":0.125},{"level":1,"id":"1_5","label":"地域活性化と世代間交流を促進する公共スペースの整備","takeaway":"地域の活性化を図るためには、子どもや高齢者が利用できる公共スペースの整備が不可欠です。子ども向けの遊び場や高齢者がリラックスできる施設を設けることで、世代を越えた交流が生まれ、地域コミュニティの結束が強化されます。また、空き家の活用や新たな住宅供給の促進、無料のコワーキングスペースの設置など、地域住民が快適に過ごせる環境を整えることが求められています。これにより、持続可能な社会の構築や地域の魅力向上が期待されます。","value":29,"parent":"0","density_rank_percentile":0.75},{"level":1,"id":"1_4","label":"人口減少と少子高齢化に対する包括的な社会的対策の推進","takeaway":"人口減少や少子高齢化がもたらす社会的および経済的影響に対する認識が高まっており、これらの問題に対処するためには、広域な公共団体の設立や子供への投資の増加が求められています。また、環境問題やポイ捨て防止に関する具体的な対策も重要視されており、持続可能な社会を実現するための取り組みが必要です。さらに、雪による影響への対策も含め、社会全体での協力が求められています。","value":25,"parent":"0","density_rank_percentile":0.625},{"level":2,"id":"2_29","label":"地域資源を活用した観光施設の充実と多様化","takeaway":"この意見グループは、赤レンガパークや夕潮台公園などの既存の地域資源を活用し、観光施設を充実させることに焦点を当てています。宿泊施設や飲食店の整備、遊びの場の提供を通じて、観光客と市民が共に楽しめる環境を整えることが求められています。","value":6,"parent":"1_8","density_rank_percentile":0.671875},{"level":2,"id":"2_57","label":"地域活性化のための大型商業施設誘致","takeaway":"この意見グループは、地域の経済活性化を目的とした大型商業施設やアウトレットの誘致に関するもので、特に東インター近くの立地が適しているとの意見が集まっています。また、具体的な店舗としてジャンカラの誘致を提案する声もあり、地域の魅力を高めるための具体的な施策が求められています。","value":4,"parent":"1_7","density_rank_percentile":0.9375},{"level":2,"id":"2_17","label":"子育て世代への包括的な経済支援と生活環境の改善","takeaway":"この意見グループは、結婚や子育てに関連する経済的支援の必要性を強調しており、特に子育て世帯が直面する経済的負担を軽減するための具体的な施策（支援金、無償化など）を提案しています。子育て世代を支えることが社会全体の福祉向上につながるという視点が共通しています。","value":5,"parent":"1_2","density_rank_percentile":0.546875},{"level":2,"id":"2_6","label":"舞鶴市の魅力向上と地域活性化戦略","takeaway":"この意見グループは、舞鶴市の住みやすさや魅力を高めるための具体的な施策に関する提案が中心です。子育て支援の充実や交通インフラの整備、地域特産品の活用、青少年育成の枠組みの構築など、舞鶴市の人口増加や地域活性化を目指す意見が集まっています。","value":10,"parent":"1_8","density_rank_percentile":0.953125},{"level":2,"id":"2_43","label":"交通インフラの整備と渋滞解消の重要性","takeaway":"この意見グループは、交通整備や道路改良の必要性に焦点を当てており、特に渋滞の解消を目的としたインフラの整備が求められています。具体的には、ロードハーディングやバイパス道路の整備を通じて、交通の流れを改善し、より快適な移動環境を実現することが強調されています。","value":5,"parent":"1_6","density_rank_percentile":0.6875},{"level":2,"id":"2_34","label":"医療介護の統合と専門性の向上","takeaway":"この意見グループは、医療介護の分野において、病院の統合や専門医療の充実を求める声が中心です。特に、ドクターヘリの完備や一つの大きな病院の設立を通じて、効率的かつ専門的な医療サービスを提供することの重要性が強調されています。","value":4,"parent":"1_2","density_rank_percentile":0.421875},{"level":2,"id":"2_56","label":"地域魅力向上による移住促進戦略","takeaway":"この意見グループは、農漁業の体験を通じて地域の自然環境や文化の魅力を伝え、移住者を増やすことを目指しています。特に加佐地区の魅力を高める取り組みが重要視されており、地域活性化と持続可能な発展に向けた具体的な施策が求められています。","value":2,"parent":"1_8","density_rank_percentile":0.375},{"level":2,"id":"2_48","label":"舞鶴駅周辺の交通インフラと再開発の必要性","takeaway":"この意見グループは、西舞鶴駅と東舞鶴駅の再開発に関する提案が中心であり、特に西舞鶴駅の東口における路線バスの導入が重要視されています。交通インフラの整備が地域の発展に寄与するとの認識が示されています。","value":2,"parent":"1_8","density_rank_percentile":0.390625},{"level":2,"id":"2_39","label":"地域教育機関の拡充と進学機会の向上","takeaway":"この意見グループは、地域における教育機関の増設を通じて、地元の子どもたちが地元の高校や大学に進学できる環境を整えることの重要性を強調しています。地域の教育機関を充実させることで、進学の選択肢を広げ、地域の人材育成を促進することが求められています。","value":4,"parent":"1_3","density_rank_percentile":0.796875},{"level":2,"id":"2_41","label":"教育者の道徳心と専門性の向上","takeaway":"この意見グループは、教育に関わる人々が道徳心を持ち、子供たちの模範となることの重要性や、指導者の育成、子供たちのつながりを促進すること、さらには特別支援教育に対する理解を深める機会の提供が必要であるという点に焦点を当てています。教育者の質を高めることが、より良い教育環境を作るための鍵であるという共通の認識が見られます。","value":4,"parent":"1_1","density_rank_percentile":0.34375},{"level":2,"id":"2_30","label":"子供育成に優しい社会環境の整備","takeaway":"この意見グループは、子供が育てやすい教育環境や社会的な支援を強化する必要性に焦点を当てています。具体的には、子供を産み育てることができる街づくりや、教育機関の充実を通じて、子供の成長を支える社会的な基盤を整えることが求められています。","value":3,"parent":"1_2","density_rank_percentile":0.75},{"level":2,"id":"2_55","label":"多様性を尊重した学校給食のオーガニック化","takeaway":"この意見グループは、学校給食のオーガニック化を通じて、食品アレルギーや感覚過敏などの多様な特性や好みを尊重し、すべての生徒が安心して食べられる選択肢を増やすことの重要性を強調しています。","value":3,"parent":"1_1","density_rank_percentile":0.171875},{"level":2,"id":"2_14","label":"地域活性化と地産地消の推進","takeaway":"この意見グループは、地元の資源を活用した地産地消の重要性や、観光業の発展を通じて地域を活性化させること、そして地域住民が自分のまちを愛し、誇りを持てる環境を整えることに焦点を当てています。また、現代の楽市楽座のような交流の場を作ることで、地域経済の活性化を図るべきという意見が共通しています。","value":4,"parent":"1_8","density_rank_percentile":0.96875},{"level":2,"id":"2_44","label":"子ども向け公共スペースの創出によるシャッター街復興","takeaway":"この意見グループは、東西のシャッター街を復興させるために、子どもたちが自由に遊べる場所を設けることの重要性を強調しています。公共スペースの設置により、地域の活性化やコミュニティの再生が期待される点が中心となっています。","value":2,"parent":"1_5","density_rank_percentile":0.78125},{"level":2,"id":"2_53","label":"地域商業の活性化と支援の重要性","takeaway":"この意見グループは、新規出店や地元の小規模店、商店街の活性化に向けた支援の必要性を強調しています。特に、店舗が復活しない理由を把握し、適切な支援を行うことで地域経済の活性化が図れるという前向きな視点が中心です。","value":2,"parent":"1_7","density_rank_percentile":0.140625},{"level":2,"id":"2_0","label":"文化・芸術の普及と地域活性化のための大規模イベント推進","takeaway":"この意見グループは、文化や芸術を身近に感じる機会を増やすことの重要性に焦点を当てています。大規模なイベントを通じて、地域の芸術活動を活性化し、参加者を誘致することで、文化的な交流や地域の活性化を図るべきだという考えが中心です。","value":2,"parent":"1_3","density_rank_percentile":0.5625},{"level":2,"id":"2_12","label":"産業発展による経済成長の促進と持続可能な革新","takeaway":"この意見グループは、産業の発展が経済成長に与える影響を強調しており、持続可能な成長を実現するためには革新が不可欠であるという考えが中心です。また、親子の関係を引き寄せることで商業的な成功を目指す必要性も示唆されています。","value":6,"parent":"1_7","density_rank_percentile":0.578125},{"level":2,"id":"2_8","label":"教育環境の充実とコミュニケーションの改善","takeaway":"この意見グループは、教育環境の向上を目指す様々な提案が含まれています。具体的には、少人数の学校の統合や生涯学習の仕組みの構築、学校生活における子どもとの対話を重視したコミュニケーションの転換、新しい図書館の活用など、教育の質を高めるための多角的なアプローチが示されています。","value":5,"parent":"1_1","density_rank_percentile":0.890625},{"level":2,"id":"2_28","label":"資格と能力を活かす社会の実現","takeaway":"この意見グループは、資格を持つ人々がその能力を十分に発揮できない現状を改善し、様々な能力や知識を持つ人々が自分の力を活かせる社会の構築を目指すことに焦点を当てています。また、誰もが意見を言いやすい仕組みを作ることが重要であると強調されています。","value":3,"parent":"1_3","density_rank_percentile":0.515625},{"level":2,"id":"2_50","label":"高齢者・子供向けの安全な観光アクセス改善","takeaway":"この意見グループは、高潮対策を進めることに加え、高齢者や子供が安全に自然の美しい景色を楽しむための観光アクセスの改善が必要であるという点に焦点を当てています。特に、通行止めになっているケーブルの改善が求められており、観光地へのアクセス向上が重要視されています。","value":2,"parent":"1_6","density_rank_percentile":0.359375},{"level":2,"id":"2_13","label":"高齢者の雇用促進と世代間交流の場の創出","takeaway":"この意見グループは、60代以上の高齢者が働ける環境を整えることの重要性に焦点を当てています。労働者不足の解消や、世代を越えた繋がりを生むための働く場所の確保が求められており、仕事の充実度を高めることが必要とされています。","value":5,"parent":"1_5","density_rank_percentile":0.859375},{"level":2,"id":"2_20","label":"産業活性化と若者の雇用創出のための企業支援","takeaway":"この意見グループは、企業誘致や起業家支援を通じて地域の産業を活性化し、若者の雇用機会を増やすことに焦点を当てています。また、研究開発を行う企業への支援や税制優遇の提供が、地域の技術力向上や理系学生のUターン促進に寄与することが期待されています。","value":4,"parent":"1_7","density_rank_percentile":0.484375},{"level":2,"id":"2_40","label":"地域発展のための自主的な運営と交流の場の創出","takeaway":"この意見グループは、地域活動において自主的に会を運営することの重要性を強調しており、人、物、金が集まることで地域が発展するという考え方が中心です。また、安全な交流の機会を作ることが地域や国の人々とのつながりを深めるために必要であるという意見も含まれています。","value":3,"parent":"1_3","density_rank_percentile":0.4375},{"level":2,"id":"2_33","label":"地域経済活性化のための大型ショッピングモール誘致","takeaway":"この意見グループは、地域の経済を活性化させるために大型ショッピングモールの誘致が必要であるという共通の認識に基づいています。ショッピングモールの増加が地域の魅力を高め、消費を促進することが期待されています。","value":2,"parent":"1_7","density_rank_percentile":0.21875},{"level":2,"id":"2_62","label":"知財関連の補助金活用促進と支援体制の構築","takeaway":"この意見グループは、知的財産関連の活動に対して既存の補助金を利用できるように制度を見直し、周知を図ることの重要性を強調しています。また、補助金を効果的に活用するための仕組み作りや、互いに支援し合える環境の整備が必要であるという点が共通しており、知財活動の活性化を目指す姿勢が見受けられます。","value":3,"parent":"1_2","density_rank_percentile":0.8125},{"level":2,"id":"2_16","label":"人口減少問題への包括的アプローチと社会的影響","takeaway":"この意見グループは、人口減少がもたらす社会的および経済的影響に対する認識を示しており、問題解決のために人を集めたり、広域な公共団体の設立を提案するなど、包括的なアプローチが必要であることを強調しています。","value":8,"parent":"1_4","density_rank_percentile":0.765625},{"level":2,"id":"2_1","label":"自然を活かした観光施設の整備と環境保全","takeaway":"この意見グループは、釣り場やグランピングなどの自然を活かしたアウトドア施設の整備を提案し、さらに自転車道路や北吸トンネルの整備、定期的な清掃活動を通じて観光名所の魅力を高めることを重視しています。また、雲海や雪景色を楽しむ観光客を増やすための施策も求められており、自然環境の保全と観光振興の両立が重要なテーマとなっています。","value":4,"parent":"1_8","density_rank_percentile":0.921875},{"level":2,"id":"2_42","label":"子育て支援の充実と多様な習い事の推進","takeaway":"この意見グループは、子どもたちの成長を支えるために、スポーツやその他の習い事を含む多様な子育て支援の必要性を強調しています。特に、病児保育などの具体的な支援策を通じて、親が安心して子育てできる環境を整えることが重要であるという意見が中心です。","value":4,"parent":"1_2","density_rank_percentile":0.265625},{"level":2,"id":"2_23","label":"公共交通機関の充実と利用促進","takeaway":"この意見グループは、公共交通機関の利用を促進するために、バスや電車の本数を増やすことや、両替機のリニューアル、タクシー料金の見直しなど、交通の利便性を向上させる具体的な提案が中心です。持続可能な移動手段としての公共交通の重要性が強調されています。","value":7,"parent":"1_6","density_rank_percentile":0.65625},{"level":2,"id":"2_45","label":"少子高齢化対策の強化と子供への投資","takeaway":"この意見グループは、少子高齢化の問題に対する認識が共有されており、特に子供に対する投資を増やすことでこの問題を改善する必要性が強調されています。また、老朽化の問題にも言及されており、社会全体の持続可能性を考慮した対策が求められています。","value":4,"parent":"1_4","density_rank_percentile":0.90625},{"level":2,"id":"2_52","label":"充実した教育環境の重要性とインターネット活用の再評価","takeaway":"この意見グループは、生徒にとっての教育環境の充実が不可欠であるという認識を共有しており、特に学校におけるインターネットを活用した教育方法の見直しが必要であるとの意見が中心です。教育の質を向上させるための具体的な施策やアプローチについての考えが示されています。","value":3,"parent":"1_1","density_rank_percentile":0.625},{"level":2,"id":"2_38","label":"子育て支援施設の充実と環境整備","takeaway":"この意見グループは、子育てを希望する人々が安心して育児を行えるような施設の充実を求める声が中心です。具体的には、子育てに必要なサポートや環境が整った施設の整備が重要であるという考えが示されています。","value":2,"parent":"1_2","density_rank_percentile":0.46875},{"level":2,"id":"2_27","label":"交通インフラの充実による移動の利便性向上","takeaway":"この意見グループは、バスや電車の本数を増やし、通勤や移動の利便性を高めることに焦点を当てています。特に、高速バスや直通バスの充実が求められており、学校や大きな施設近くに駅を設けることで、住民や移住者にとってのアクセスの向上が期待されています。","value":4,"parent":"1_6","density_rank_percentile":0.71875},{"level":2,"id":"2_63","label":"リモートワークと高齢者向け施設の充実","takeaway":"この意見グループは、リモートワークを支えるための施設の充実と、高齢者が安心してリラックスできる環境の整備が必要であるという点に焦点を当てています。特に、リモートワークの普及に伴い、働く場所の選択肢を増やすことと、高齢者に配慮した施設の設計が求められていることが共通のテーマとなっています。","value":2,"parent":"1_5","density_rank_percentile":0.328125},{"level":2,"id":"2_18","label":"空き家活用による住宅供給の促進","takeaway":"この意見グループは、空き家を有効活用することで新たな住宅供給を促進し、住環境の改善や地域活性化を図るべきだという考えが中心です。空き家マッチングの推進により、住宅不足の解消や地域の魅力向上が期待されています。","value":2,"parent":"1_5","density_rank_percentile":0.640625},{"level":2,"id":"2_10","label":"交通インフラの充実と再開発の必要性","takeaway":"この意見グループは、交通の便を向上させるための再開発や公共交通の充実に関する提案が中心です。具体的には、交通手段の増加や鉄道駅の設置を通じて、地域の交通インフラを強化し、利便性を高めることが求められています。","value":6,"parent":"1_6","density_rank_percentile":0.828125},{"level":2,"id":"2_11","label":"市民のための無料コワーキング・休憩スペースの提案","takeaway":"この意見グループは、市民が利用できる無料のコワーキングスペースや休憩スペースの設置を求める声が中心です。市民の生活の質を向上させるための公共の場の重要性や、地域コミュニティの活性化を図るための具体的な提案が含まれています。","value":2,"parent":"1_5","density_rank_percentile":0.453125},{"level":2,"id":"2_2","label":"教育環境の充実と多様な進路選択の促進","takeaway":"この意見グループは、教育の重要性を強調し、学校の費用削減や教育環境の整備を通じて、より良い学びの場を提供することが求められています。また、失敗を価値ある経験として捉える文化の醸成や、進路選択の多様化を図ることが教育環境の充実に寄与するという視点が中心です。","value":5,"parent":"1_1","density_rank_percentile":0.59375},{"level":2,"id":"2_54","label":"年齢に応じた自然体験の充実と女性のライフスタイル向上","takeaway":"この意見グループは、女性が年齢に応じて異なるアクティビティを楽しむことが重要であり、特に自然を活用したアクティビティの充実が求められている点に焦点を当てています。自然環境を生かした活動が、女性の生活の質を向上させる手段として提案されています。","value":2,"parent":"1_5","density_rank_percentile":0.40625},{"level":2,"id":"2_4","label":"臨海部開発と水域管理の重要性","takeaway":"この意見グループは、臨海部の開発を推進する必要性と、海と川の境界に網を張ることで水域の管理を強化することに焦点を当てています。臨海部の開発は地域経済の活性化に寄与し、同時に水域の保護や管理の重要性を訴える意見が含まれています。","value":2,"parent":"1_6","density_rank_percentile":0.203125},{"level":2,"id":"2_47","label":"プレイバックフェスの持続可能な運営とインフラ整備","takeaway":"この意見グループは、プレイバックフェスの継続的な実施を支持し、そのために必要なインフラの再整備を提案しています。フェスの持続可能性を高めるためには、適切なインフラが不可欠であるという認識が共有されています。","value":2,"parent":"1_5","density_rank_percentile":0.15625},{"level":2,"id":"2_36","label":"公共施設と安全・快適性の向上","takeaway":"この意見グループは、住宅や公共施設、スポーツ施設の安全性や快適性を向上させる必要性に加え、公園や広場の整備、公共施設の充実、施設の増設や整備に関する具体的な提案が含まれています。これにより、地域住民の生活環境が改善されることを目指しています。","value":5,"parent":"1_5","density_rank_percentile":0.703125},{"level":2,"id":"2_58","label":"市民の自立と協力による持続可能な社会の構築","takeaway":"この意見グループは、都市における市民の協力と自立を重視し、個々の市民が助け合いながら備えを強化することの重要性を訴えています。また、適度な休暇や休息を取れる社会の実現を通じて、より持続可能で健康的なコミュニティを目指す姿勢が表れています。","value":3,"parent":"1_5","density_rank_percentile":1},{"level":2,"id":"2_5","label":"商店街の活性化と多様な店舗の誘致","takeaway":"この意見グループは、商店街の活性化を目指し、飲食店や娯楽施設などの多様な店舗のバリエーションを増やすこと、また商店街の整備や企業誘致を通じて地域の活気を取り戻す必要性に焦点を当てています。地域の発展と人口増加を促進するための具体的な施策が求められています。","value":7,"parent":"1_7","density_rank_percentile":0.734375},{"level":2,"id":"2_21","label":"通学路の安全性向上とインフラ整備の必要性","takeaway":"この意見グループは、通学路の安全確保に向けた具体的なインフラ整備の必要性に焦点を当てています。歩道や自転車道の整備、雪対策、さらには水道配管の点検など、通学路の安全性を高めるための多角的なアプローチが求められています。","value":4,"parent":"1_6","density_rank_percentile":0.984375},{"level":2,"id":"2_7","label":"小児医療の質とアクセス向上の必要性","takeaway":"この意見は、小児医療に対する充実が求められていることを示しており、特に小児患者に対する医療サービスの質やアクセスの向上が重要であるという認識が強調されています。","value":1,"parent":"1_2","density_rank_percentile":0.015625},{"level":2,"id":"2_46","label":"地域連携による青少年育成のための研修と交流の促進","takeaway":"この意見グループは、地域全体で青少年の健全な育成を目指すために、研修や合同合宿を通じて指導者や青少年団体が共に学び、情報交換を行うことの重要性を強調しています。地域の連携を深めることで、より効果的な育成環境を整える必要性が示されています。","value":2,"parent":"1_3","density_rank_percentile":0.296875},{"level":2,"id":"2_31","label":"ポイ捨て防止と環境保護の重要性","takeaway":"この意見グループは、ポイ捨て行為が環境に与える悪影響に対する懸念と、それを防ぐための具体的な対策（罰金制度の導入や啓発活動など）の必要性を強調しています。ポイ捨てを減らすことの重要性が共通して認識されており、環境保護の観点からの意識向上が求められています。","value":4,"parent":"1_4","density_rank_percentile":0.3125},{"level":2,"id":"2_24","label":"地域の発展と歴史的建造物の活用促進","takeaway":"この意見グループは、地域の発展に向けて新たな建物の増設を提案しつつ、歴史的建造物の魅力を高めることが重要であると考えています。新しい建物の建設は地域の活性化に寄与し、歴史的建造物のアピールを強化することで、観光や地域文化の振興にもつながるという視点が中心です。","value":2,"parent":"1_5","density_rank_percentile":0.28125},{"level":2,"id":"2_22","label":"中学生向け遊び場の充実と多様化","takeaway":"この意見グループは、中学生や子供たちが楽しめる遊び場や施設の不足を指摘し、彼らの遊びや交流の場を増やす必要性を強調しています。特に、年齢に適したアクティビティや安全な環境を提供することが求められており、地域社会における子供たちの健全な成長を促進するための具体的な施策が必要とされています。","value":1,"parent":"1_3","density_rank_percentile":0.03125},{"level":2,"id":"2_3","label":"少子高齢化による社会構造の変化と就職市場への影響","takeaway":"この意見グループは、少子高齢化が社会全体に与える影響の重要性を強調しており、特に就職先の衰退という具体的な問題に焦点を当てています。少子高齢化が進むことで労働力人口が減少し、企業の成長や雇用機会にどのような影響を及ぼすかについての懸念が表れています。","value":2,"parent":"1_4","density_rank_percentile":0.53125},{"level":2,"id":"2_59","label":"海洋環境保護と美化の重要性","takeaway":"この意見は、海の周りを綺麗にすることの必要性を強調しており、環境保護や美化に対する意識の高まりを反映しています。海洋環境の保全は、自然の美しさを保つだけでなく、生態系の健康や人々の生活の質にも直結する重要なテーマです。","value":1,"parent":"1_6","density_rank_percentile":0.046875},{"level":2,"id":"2_60","label":"若者向けの魅力的な雇用機会の創出","takeaway":"この意見は、若い人々が働きたいと感じる職場環境や雇用機会を提供することの重要性を強調しています。若者を惹きつけるためには、魅力的な職場文化や成長の機会を持つ企業を誘致する必要があるという視点が中心です。","value":1,"parent":"1_3","density_rank_percentile":0.0625},{"level":2,"id":"2_19","label":"給食の質向上と無償化による食育の新しい価値観","takeaway":"この意見グループは、給食を楽しく食べることを重視し、従来の好き嫌いをなくすという古い価値観を見直す必要性を訴えています。また、給食の無償化だけでなく、子どもたちが美味しいと感じる食事を提供することが重要であるという点が強調されています。","value":3,"parent":"1_1","density_rank_percentile":0.1875},{"level":2,"id":"2_15","label":"多様性と人権尊重の共生社会の構築","takeaway":"この意見グループは、異なる文化や世代、生物との交流を通じて、多様な価値観を受け入れ、尊重することの重要性を強調しています。また、人間理解を深めることで人権が尊重される社会の実現を目指す姿勢が見受けられ、共生のための土壌作りに対する前向きな提案が中心です。","value":2,"parent":"1_3","density_rank_percentile":0.234375},{"level":2,"id":"2_35","label":"地域活性化と治安改善のための都市再生プロジェクト","takeaway":"この意見グループは、市役所の改造や旧スキー場の整備を通じて、地域の活性化と治安の改善を目指す具体的な提案が中心です。新たなホテルやショッピングモールの設置により、地域の魅力を高め、住民や観光客が安心して訪れることのできる街づくりを呼びかけています。","value":3,"parent":"1_8","density_rank_percentile":0.875},{"level":2,"id":"2_51","label":"舞鶴湾を一望する観光ロープウェイの整備","takeaway":"この意見グループは、赤レンガパーク周辺や旧スキー場、atick、夕潮台公園をロープウェイで結ぶことにより、舞鶴湾の美しい景観を楽しむ移動手段を提供し、観光名所としての魅力を高めることの重要性を強調しています。","value":2,"parent":"1_8","density_rank_percentile":0.5},{"level":2,"id":"2_26","label":"教育環境の改善と充実","takeaway":"この意見グループは、教育の質を向上させるために、教育環境の改善や充実が必要であるという共通の認識を示しています。教育しやすい環境を整えることが、学習効果を高めるための重要な要素であるという点に焦点を当てています。","value":3,"parent":"1_1","density_rank_percentile":0.609375},{"level":2,"id":"2_9","label":"持続可能な環境問題への取り組みと解決策の必要性","takeaway":"この意見グループは、環境問題、特にゴミの問題や地球温暖化に対する深刻な認識を示しており、持続可能な解決策や対策の必要性が強調されています。また、リサイクルや廃棄物削減の重要性も指摘されており、環境を大切にする意識が高まっていることが伺えます。","value":6,"parent":"1_4","density_rank_percentile":0.25},{"level":2,"id":"2_32","label":"舞鶴の地域活性化と若者定住促進のための遊び場整備","takeaway":"この意見グループは、舞鶴の過疎化を防ぎ、若者が地域に留まるための魅力的な遊び場や商業施設の必要性に焦点を当てています。地域の活性化を図るために、新しい施設を整備することが重要であるという前向きな提案が中心です。","value":2,"parent":"1_8","density_rank_percentile":0.84375},{"level":2,"id":"2_49","label":"雪による影響と対策の必要性","takeaway":"この意見は、雪がもたらすさまざまな問題に対して取り組む必要があるという認識を示しています。雪による交通障害や生活への影響を軽減するための具体的な対策や準備が求められていることが中心テーマです。","value":1,"parent":"1_4","density_rank_percentile":0.078125},{"level":2,"id":"2_37","label":"自然保護の重要性と持続可能な未来","takeaway":"この意見は、自然環境の保護が重要であるという認識を示しており、持続可能な未来を築くためには自然を守る必要があるという考えが中心です。環境保護の観点から、自然の価値やその保全の重要性についての意識が高まっていることが反映されています。","value":1,"parent":"1_5","density_rank_percentile":0.09375},{"level":2,"id":"2_25","label":"高齢者に優しい住環境の整備","takeaway":"この意見は、高齢者が快適に過ごせるような住環境の整備に焦点を当てています。具体的には、バリアフリー設計や安全な公共スペースの確保、生活支援サービスの充実など、高齢者のニーズに応じた建設や改修が求められています。","value":1,"parent":"1_5","density_rank_percentile":0.109375},{"level":2,"id":"2_61","label":"少子化対策としての大学誘致による地域活性化","takeaway":"この意見グループは、少子化の影響を受ける地域において、大学などの教育機関を誘致することで、若者の流入を促し、結果として周辺の店舗や宿泊施設、アルバイト先の活性化が期待できるという前向きな視点が中心です。","value":1,"parent":"1_3","density_rank_percentile":0.125}],"comments":{},"propertyMap":{},"translations":{},"overview":"舞鶴市の地域活性化に向けた意見は、観光資源の活用や地域経済の振興、子育て支援、交通インフラの整備など多岐にわたります。特に、観光施設の充実や地元産業の支援、医療介護の充実が重要視されており、地域の魅力向上が期待されています。また、教育環境の改善や世代間交流の促進、人口減少対策も重要なテーマとして挙げられています。これらの取り組みを通じて、持続可能で住みやすい地域社会の実現が目指されています。","config":{"name":"99b00a75-d481-48bf-9133-8976f6f7720c","input":"99b00a75-d481-48bf-9133-8976f6f7720c","question":"②自分が市長なら、2040年に向けてこんな課題に取り組む【2/15 15:00 更新】","intro":"舞鶴市の成長戦略は、地域経済の活性化、教育環境の充実、子ども育成と高齢者支援、交通利便性の向上、地域社会の活性化、観光施設の充実、持続可能な社会の実現に向けた多様な施策を含んでいます。地場企業支援や医療・福祉体制の強化、公共交通の整備、地域資源の活用が重要視されており、地域全体での協力が求められています。特に、少子高齢化や環境問題への包括的アプローチが強調され、持続可能な未来の構築が期待されています。\n分析対象となったデータの件数は528件で、これらのデータに対してOpenAI API (gpt-4o-mini)を用いて212件の意見（議論）を抽出し、クラスタリングを行った。\n","model":"gpt-4o-mini","provider":"openai","is_pubcom":true,"is_embedded_at_local":false,"local_llm_address":null,"extraction":{"prompt":"あなたは専門的なリサーチアシスタントです。与えられたテキストから、意見を抽出して整理してください。\n\n# 指示\n* 入出力の例に記載したような形式で文字列のリストを返してください\n  * 必要な場合は2つの別個の意見に分割してください。多くの場合は1つの議論にまとめる方が望ましいです。\n* 整理した意見は日本語で出力してください\n\n## 入出力の例\n/human\n\nAIテクノロジーは、そのライフサイクル全体における環境負荷を削減することに焦点を当てて開発されるべきです。\n\n/ai\n\n{\n  \"extractedOpinionList\": [\n    \"AIテクノロジーは、そのライフサイクル全体における環境負荷を削減することに焦点を当てて開発されるべきです。\"\n  ]\n}\n\n/human\n\nAIの能力、限界、倫理的考慮事項について、市民を教育する必要がある。また、教育できる人材を養成する必要がある。\n\n/ai\n\n{\n  \"extractedOpinionList\": [\n    \"AIの能力、限界、倫理的考慮事項について、市民を教育すべき\",\n    \"AIに関する教育をできる人材を養成すべき\"\n  ]\n}\n\n/human\n\nAIはエネルギーグリッドを最適化し、無駄や炭素排出を削減できます。\n\n/ai\n\n{\n  \"extractedOpinionList\": [\n    \"AIはエネルギーグリッドを最適化して炭素排出を削減できる\"\n  ]\n}\n","workers":30,"limit":528,"properties":[],"categories":{},"category_batch_size":5,"source_code":"$19","model":"gpt-4o-mini"},"hierarchical_clustering":{"cluster_nums":[8,64],"source_code":"$1a"},"hierarchical_initial_labelling":{"prompt":"あなたはKJ法が得意なデータ分析者です。userのinputはグループに集まったラベルです。なぜそのラベルが一つのグループであるか解説し、表札（label）をつけてください。\n表札については、グループ内の具体的な論点や特徴を反映した、具体性の高い名称を考案してください。\n出力はJSONとし、フォーマットは以下のサンプルを参考にしてください。\n\n\n# サンプルの入出力\n## 入力例\n- 手作業での意見分析は時間がかかりすぎる。AIで効率化できると嬉しい\n- 今のやり方だと分析に工数がかかりすぎるけど、AIならコストをかけずに分析できそう\n- AIが自動で意見を整理してくれると楽になって嬉しい\n\n\n## 出力例\n{\n    \"label\": \"AIによる業務効率の大幅向上とコスト効率化\",\n    \"description\": \"この意見グループは、従来の手作業による意見分析と比較して、AIによる自動化で分析プロセスが効率化され、作業時間の短縮や運用コストの効率化が実現される点に対する前向きな評価が中心です。\"\n}\n","sampling_num":30,"workers":30,"source_code":"$1b","model":"gpt-4o-mini"},"hierarchical_merge_labelling":{"prompt":"あなたはデータ分析のエキスパートです。\n現在、テキストデータの階層クラスタリングを行っています。\n下層のクラスタ（意見グループ）のタイトルと説明、およびそれらのクラスタが所属する上層のクラスタのテキストのサンプルを与えるので、上層のクラスタのタイトルと説明を作成してください。\n\n# 指示\n- 統合後のクラスタ名は、統合前のクラスタ名称をそのまま引用せず、内容に基づいた新たな名称にしてください。\n- タイトルには、具体的な事象・行動（例：地域ごとの迅速対応、復興計画の着実な進展、効果的な情報共有・地域協力など）を含めてください\n  - 可能な限り具体的な表現を用いるようにし、抽象的な表現は避けてください\n    - 「多様な意見」などの抽象的な表現は避けてください\n- 出力例に示したJSON形式で出力してください\n\n\n# サンプルの入出力\n## 入力例\n- 「顧客フィードバックの自動集約」: この意見グループは、SNSやオンラインレビューなどから集めた大量の意見をAIが瞬時に解析し、企業が市場のトレンドや顧客の要望を即時に把握できる点についての期待を示しています。\n- 「AIによる業務効率の大幅向上とコスト効率化」: この意見グループは、従来の手作業による意見分析と比較して、AIによる自動化で分析プロセスが効率化され、作業時間の短縮や運用コストの効率化が実現される点に対する前向きな評価が中心です。\n\n## 出力例\n{\n    \"label\": \"AI技術の導入による意見分析の効率化への期待\",\n    \"description\": \"大量の意見やフィードバックから迅速に洞察を抽出できるため、企業や自治体が消費者や市民の声を的確に把握し、戦略的な意思決定やサービス改善が可能になります。また、従来の手法と比べて作業負荷が軽減され、業務効率の向上やコスト削減といった実際の便益が得られると期待されています。\"\n}\n","sampling_num":30,"workers":30,"source_code":"$1c","model":"gpt-4o-mini"},"hierarchical_overview":{"prompt":"/system \n\nあなたはシンクタンクで働く専門のリサーチアシスタントです。\nチームは特定のテーマに関してパブリック・コンサルテーションを実施し、異なる選択肢の意見グループを分析し始めています。\nこれから意見グループのリストとその簡単な分析が提供されます。\nあなたの仕事は、調査結果の簡潔な要約を返すことです。要約は非常に簡潔に（最大で1段落、最大4文）まとめ、無意味な言葉を避けてください。\n出力は日本語で行ってください。\n","source_code":"$1d","model":"gpt-4o-mini"},"hierarchical_aggregation":{"sampling_num":30,"hidden_properties":{},"source_code":"$1e"},"enable_source_link":false,"output_dir":"99b00a75-d481-48bf-9133-8976f6f7720c","skip-interaction":true,"without-html":true,"embedding":{"model":"text-embedding-3-small","source_code":"$1f"},"hierarchical_visualization":{"replacements":[],"source_code":"import subprocess\n\n\ndef hierarchical_visualization(config):\n    output_dir = config[\"output_dir\"]\n    cwd = \"../report\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(\n            command,\n            shell=True,\n            cwd=cwd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            universal_newlines=True,\n        )\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == \"\" and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":true,"reason":"not trace of previous run"},{"step":"embedding","run":true,"reason":"not trace of previous run"},{"step":"hierarchical_clustering","run":true,"reason":"not trace of previous run"},{"step":"hierarchical_initial_labelling","run":true,"reason":"not trace of previous run"},{"step":"hierarchical_merge_labelling","run":true,"reason":"not trace of previous run"},{"step":"hierarchical_overview","run":true,"reason":"not trace of previous run"},{"step":"hierarchical_aggregation","run":true,"reason":"not trace of previous run"},{"step":"hierarchical_visualization","run":false,"reason":"skipping html output"}],"status":"running","start_time":"2026-02-15T04:06:34.004289","completed_jobs":[{"step":"extraction","completed":"2026-02-15T04:15:08.113062","duration":514.100462,"params":{"prompt":"あなたは専門的なリサーチアシスタントです。与えられたテキストから、意見を抽出して整理してください。\n\n# 指示\n* 入出力の例に記載したような形式で文字列のリストを返してください\n  * 必要な場合は2つの別個の意見に分割してください。多くの場合は1つの議論にまとめる方が望ましいです。\n* 整理した意見は日本語で出力してください\n\n## 入出力の例\n/human\n\nAIテクノロジーは、そのライフサイクル全体における環境負荷を削減することに焦点を当てて開発されるべきです。\n\n/ai\n\n{\n  \"extractedOpinionList\": [\n    \"AIテクノロジーは、そのライフサイクル全体における環境負荷を削減することに焦点を当てて開発されるべきです。\"\n  ]\n}\n\n/human\n\nAIの能力、限界、倫理的考慮事項について、市民を教育する必要がある。また、教育できる人材を養成する必要がある。\n\n/ai\n\n{\n  \"extractedOpinionList\": [\n    \"AIの能力、限界、倫理的考慮事項について、市民を教育すべき\",\n    \"AIに関する教育をできる人材を養成すべき\"\n  ]\n}\n\n/human\n\nAIはエネルギーグリッドを最適化し、無駄や炭素排出を削減できます。\n\n/ai\n\n{\n  \"extractedOpinionList\": [\n    \"AIはエネルギーグリッドを最適化して炭素排出を削減できる\"\n  ]\n}\n","workers":30,"limit":528,"properties":[],"categories":{},"category_batch_size":5,"source_code":"$20","model":"gpt-4o-mini"},"token_usage":71109},{"step":"embedding","completed":"2026-02-15T04:15:44.907002","duration":36.78762,"params":{"model":"text-embedding-3-small","source_code":"$21"},"token_usage":0},{"step":"hierarchical_clustering","completed":"2026-02-15T04:41:00.738593","duration":1515.822581,"params":{"cluster_nums":[8,64],"source_code":"$22"},"token_usage":0},{"step":"hierarchical_initial_labelling","completed":"2026-02-15T04:42:05.487020","duration":64.742433,"params":{"prompt":"あなたはKJ法が得意なデータ分析者です。userのinputはグループに集まったラベルです。なぜそのラベルが一つのグループであるか解説し、表札（label）をつけてください。\n表札については、グループ内の具体的な論点や特徴を反映した、具体性の高い名称を考案してください。\n出力はJSONとし、フォーマットは以下のサンプルを参考にしてください。\n\n\n# サンプルの入出力\n## 入力例\n- 手作業での意見分析は時間がかかりすぎる。AIで効率化できると嬉しい\n- 今のやり方だと分析に工数がかかりすぎるけど、AIならコストをかけずに分析できそう\n- AIが自動で意見を整理してくれると楽になって嬉しい\n\n\n## 出力例\n{\n    \"label\": \"AIによる業務効率の大幅向上とコスト効率化\",\n    \"description\": \"この意見グループは、従来の手作業による意見分析と比較して、AIによる自動化で分析プロセスが効率化され、作業時間の短縮や運用コストの効率化が実現される点に対する前向きな評価が中心です。\"\n}\n","sampling_num":30,"workers":30,"source_code":"$23","model":"gpt-4o-mini"},"token_usage":45872},{"step":"hierarchical_merge_labelling","completed":"2026-02-15T04:42:10.220182","duration":4.724627,"params":{"prompt":"あなたはデータ分析のエキスパートです。\n現在、テキストデータの階層クラスタリングを行っています。\n下層のクラスタ（意見グループ）のタイトルと説明、およびそれらのクラスタが所属する上層のクラスタのテキストのサンプルを与えるので、上層のクラスタのタイトルと説明を作成してください。\n\n# 指示\n- 統合後のクラスタ名は、統合前のクラスタ名称をそのまま引用せず、内容に基づいた新たな名称にしてください。\n- タイトルには、具体的な事象・行動（例：地域ごとの迅速対応、復興計画の着実な進展、効果的な情報共有・地域協力など）を含めてください\n  - 可能な限り具体的な表現を用いるようにし、抽象的な表現は避けてください\n    - 「多様な意見」などの抽象的な表現は避けてください\n- 出力例に示したJSON形式で出力してください\n\n\n# サンプルの入出力\n## 入力例\n- 「顧客フィードバックの自動集約」: この意見グループは、SNSやオンラインレビューなどから集めた大量の意見をAIが瞬時に解析し、企業が市場のトレンドや顧客の要望を即時に把握できる点についての期待を示しています。\n- 「AIによる業務効率の大幅向上とコスト効率化」: この意見グループは、従来の手作業による意見分析と比較して、AIによる自動化で分析プロセスが効率化され、作業時間の短縮や運用コストの効率化が実現される点に対する前向きな評価が中心です。\n\n## 出力例\n{\n    \"label\": \"AI技術の導入による意見分析の効率化への期待\",\n    \"description\": \"大量の意見やフィードバックから迅速に洞察を抽出できるため、企業や自治体が消費者や市民の声を的確に把握し、戦略的な意思決定やサービス改善が可能になります。また、従来の手法と比べて作業負荷が軽減され、業務効率の向上やコスト削減といった実際の便益が得られると期待されています。\"\n}\n","sampling_num":30,"workers":30,"source_code":"$24","model":"gpt-4o-mini"},"token_usage":19395},{"step":"hierarchical_overview","completed":"2026-02-15T04:42:14.326205","duration":4.098654,"params":{"prompt":"/system \n\nあなたはシンクタンクで働く専門のリサーチアシスタントです。\nチームは特定のテーマに関してパブリック・コンサルテーションを実施し、異なる選択肢の意見グループを分析し始めています。\nこれから意見グループのリストとその簡単な分析が提供されます。\nあなたの仕事は、調査結果の簡潔な要約を返すことです。要約は非常に簡潔に（最大で1段落、最大4文）まとめ、無意味な言葉を避けてください。\n出力は日本語で行ってください。\n","source_code":"$25","model":"gpt-4o-mini"},"token_usage":1999}],"total_token_usage":138375,"token_usage_input":123139,"token_usage_output":15236,"lock_until":"2026-02-15T04:47:14.338712","current_job":"hierarchical_aggregation","current_job_started":"2026-02-15T04:42:14.338690","estimated_cost":0.02761245,"current_job_progress":null,"current_jop_tasks":null},"comment_num":528,"visibility":"public"}}],"$L26","$L27","$L28","$L29"]}],"$L2a"]
2b:I[49985,["150","static/chunks/59650de3-92bcb3811df53909.js","771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","732","static/chunks/732-1930f1f7bd6746a5.js","619","static/chunks/619-f072ac750404f9da.js","909","static/chunks/909-5e57b886fe664200.js","13","static/chunks/13-f12e2db1f59fda05.js","785","static/chunks/785-90bb983d5bf6562b.js","767","static/chunks/767-6b739569ff79f765.js","609","static/chunks/609-e6afbba7cf646b18.js","182","static/chunks/app/%5Bslug%5D/page-2d806954bbec0f0a.js"],"Analysis"]
2c:I[68443,["150","static/chunks/59650de3-92bcb3811df53909.js","771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","732","static/chunks/732-1930f1f7bd6746a5.js","619","static/chunks/619-f072ac750404f9da.js","909","static/chunks/909-5e57b886fe664200.js","13","static/chunks/13-f12e2db1f59fda05.js","785","static/chunks/785-90bb983d5bf6562b.js","767","static/chunks/767-6b739569ff79f765.js","609","static/chunks/609-e6afbba7cf646b18.js","182","static/chunks/app/%5Bslug%5D/page-2d806954bbec0f0a.js"],"Separator"]
2e:I[27787,["150","static/chunks/59650de3-92bcb3811df53909.js","771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","732","static/chunks/732-1930f1f7bd6746a5.js","619","static/chunks/619-f072ac750404f9da.js","909","static/chunks/909-5e57b886fe664200.js","13","static/chunks/13-f12e2db1f59fda05.js","785","static/chunks/785-90bb983d5bf6562b.js","767","static/chunks/767-6b739569ff79f765.js","609","static/chunks/609-e6afbba7cf646b18.js","182","static/chunks/app/%5Bslug%5D/page-2d806954bbec0f0a.js"],"Footer"]
26:["$","$L2b",null,{"result":"$8:1:props:children:1:props:result"}]
27:["$","$L14",null,{"w":"fit-content","mx":"auto","children":["$","$L6",null,{"href":"/","children":["$","$L7",null,{"variant":"outline","size":"md","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-chevron-left","children":[["$","path","1wnfg3",{"d":"m15 18-6-6 6-6"}],"$undefined"]}],"一覧へ戻る"]}]}]}]
28:["$","$L2c",null,{"my":12,"maxW":"750px","mx":"auto"}]
29:["$","$L14",null,{"maxW":"750px","mx":"auto","mb":24,"children":"$L2d"}]
2a:["$","$L2e",null,{"meta":{"reporter":"「#みんなでつくる舞鶴2040」プロジェクト","message":"この取組では、みなさま一人ひとりの「2040年の舞鶴ってこうなってほしいな」「こんなことやってみたい！」といった想いを募集します。","webLink":"https://maizuru2040.jp/wordpress/","privacyLink":"/","termsLink":null,"brandColor":"#e7adb7","isDefault":false}}]
2f:I[24982,["150","static/chunks/59650de3-92bcb3811df53909.js","771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","732","static/chunks/732-1930f1f7bd6746a5.js","619","static/chunks/619-f072ac750404f9da.js","909","static/chunks/909-5e57b886fe664200.js","13","static/chunks/13-f12e2db1f59fda05.js","785","static/chunks/785-90bb983d5bf6562b.js","767","static/chunks/767-6b739569ff79f765.js","609","static/chunks/609-e6afbba7cf646b18.js","182","static/chunks/app/%5Bslug%5D/page-2d806954bbec0f0a.js"],"ReporterContent"]
2d:["$","$L2f",null,{"meta":"$2a:props:meta","children":"$L30"}]
31:I[21863,["150","static/chunks/59650de3-92bcb3811df53909.js","771","static/chunks/771-6df7383af9cb22cb.js","302","static/chunks/302-413e4f1ef39e273a.js","732","static/chunks/732-1930f1f7bd6746a5.js","619","static/chunks/619-f072ac750404f9da.js","909","static/chunks/909-5e57b886fe664200.js","13","static/chunks/13-f12e2db1f59fda05.js","785","static/chunks/785-90bb983d5bf6562b.js","767","static/chunks/767-6b739569ff79f765.js","609","static/chunks/609-e6afbba7cf646b18.js","182","static/chunks/app/%5Bslug%5D/page-2d806954bbec0f0a.js"],"Image"]
30:["$","$L31",null,{"src":"/kouchouAI-reports/meta/reporter.png","alt":"「#みんなでつくる舞鶴2040」プロジェクト","maxW":"150px"}]
c:{"metadata":[["$","title","0",{"children":"②自分が市長なら、2040年に向けてこんな課題に取り組む【2/15 15:00 更新】 - 「#みんなでつくる舞鶴2040」プロジェクト"}],["$","meta","1",{"name":"description","content":"舞鶴市の地域活性化に向けた意見は、観光資源の活用や地域経済の振興、子育て支援、交通インフラの整備など多岐にわたります。特に、観光施設の充実や地元産業の支援、医療介護の充実が重要視されており、地域の魅力向上が期待されています。また、教育環境の改善や世代間交流の促進、人口減少対策も重要なテーマとして挙げられています。これらの取り組みを通じて、持続可能で住みやすい地域社会の実現が目指されています。"}],["$","meta","2",{"property":"og:title","content":"②自分が市長なら、2040年に向けてこんな課題に取り組む【2/15 15:00 更新】 - 「#みんなでつくる舞鶴2040」プロジェクト"}],["$","meta","3",{"property":"og:description","content":"舞鶴市の地域活性化に向けた意見は、観光資源の活用や地域経済の振興、子育て支援、交通インフラの整備など多岐にわたります。特に、観光施設の充実や地元産業の支援、医療介護の充実が重要視されており、地域の魅力向上が期待されています。また、教育環境の改善や世代間交流の促進、人口減少対策も重要なテーマとして挙げられています。これらの取り組みを通じて、持続可能で住みやすい地域社会の実現が目指されています。"}],["$","meta","4",{"property":"og:image","content":"http://localhost:3000/99b00a75-d481-48bf-9133-8976f6f7720c/opengraph-image.png"}],["$","meta","5",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","6",{"name":"twitter:title","content":"②自分が市長なら、2040年に向けてこんな課題に取り組む【2/15 15:00 更新】 - 「#みんなでつくる舞鶴2040」プロジェクト"}],["$","meta","7",{"name":"twitter:description","content":"舞鶴市の地域活性化に向けた意見は、観光資源の活用や地域経済の振興、子育て支援、交通インフラの整備など多岐にわたります。特に、観光施設の充実や地元産業の支援、医療介護の充実が重要視されており、地域の魅力向上が期待されています。また、教育環境の改善や世代間交流の促進、人口減少対策も重要なテーマとして挙げられています。これらの取り組みを通じて、持続可能で住みやすい地域社会の実現が目指されています。"}],["$","meta","8",{"name":"twitter:image","content":"http://localhost:3000/99b00a75-d481-48bf-9133-8976f6f7720c/opengraph-image.png"}]],"error":null,"digest":"$undefined"}
11:"$c:metadata"
